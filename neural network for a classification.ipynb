{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXPUlLg7PHAF"
   },
   "source": [
    "The network is trained using minibatch stochastic gradient descent.\n",
    "\n",
    "\n",
    "Network specification:\n",
    "\n",
    "1.   Input layer - one hidden layer - output layer\n",
    "2.   Activation functions: for hidden layer \"ReLU\" and for output layer \"softmax\"\n",
    "3.   Loss function: categorical cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from matplotlib import pyplot\n",
    "import math\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "x, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = (x/255).astype('float32')\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (59500, 784)\n",
      "Y_train: (59500, 10)\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X , train_y, test_y = train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "print('X_train: ' + str(train_X.shape))\n",
    "print('Y_train: ' + str(train_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x\n",
    "y1 = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "id": "s8Mq_ZnWWVzU"
   },
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    exps = np.exp(X - np.max(X))\n",
    "    return exps/np.sum(exps,axis=0)\n",
    "\n",
    "def d_softmax(x):\n",
    "    exp_element=np.exp(x-x.max())\n",
    "    return exp_element/np.sum(exp_element,axis=0)*(1-exp_element/np.sum(exp_element,axis=0))\n",
    "\n",
    "def D_relu(x):\n",
    "    x[x <= 0] = 0\n",
    "    x[x > 0] = 1\n",
    "    return x\n",
    "\n",
    "def relu(X):\n",
    "    return np.maximum(0.0, X)\n",
    "\n",
    "def L2(w1, w2, rate = 0.00001):\n",
    "    w1 = np.array(w1)**2\n",
    "    w2 = np.array(w2)**2\n",
    "    return (rate * (np.sum(w1) + np.sum(w2)))/2\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(np.exp(-x)+1)    \n",
    "\n",
    "def d_sigmoid(x):\n",
    "    return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "\n",
    "def loss(predicted, target):\n",
    "    return target * np.log(predicted + 1e-8)\n",
    "\n",
    "def d_loss(predicted, target):\n",
    "    return predicted - target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateWeights(s, e):\n",
    "    we = []\n",
    "    for w in range(0, e):\n",
    "        f = []\n",
    "        for u in range(0, s):\n",
    "            f.append(np.random.rand())\n",
    "        we.append(f)  \n",
    "    return we\n",
    "\n",
    "def batchGenarator(data, target,  batchSize = 10):\n",
    "    sample=np.random.randint(0,data.shape[0],size=(batchSize))\n",
    "    x=data[sample]\n",
    "    y=target[sample]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(weightsInputLayer,\n",
    "             weightsOutputLayer,\n",
    "             data, target, alpha, logs = False):\n",
    "\n",
    "    H, A, H_OUTPUT, A_OUTPUT, loss_entropy = forward_pass(weightsInputLayer,\n",
    "                                                          weightsOutputLayer,\n",
    "                                                          data, target, logs = logs)\n",
    "    pred = np.argmax(A_OUTPUT, axis=1)\n",
    "    Y = np.argmax(target, axis=1)\n",
    "    accuracy = (pred == Y).mean()\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def getNumberForBatch(data, batchSize):\n",
    "    all_batches = data.shape[0] // batchSize \n",
    "    if data.shape[0] % batchSize != 0:\n",
    "        all_batches += 1    \n",
    "        \n",
    "    return all_batches\n",
    "\n",
    "def L2_regu(weightsInputLayer, lambda_L2 = 0.0001, isL2=False):\n",
    "    return weightsInputLayer * lambda_L2\n",
    "\n",
    "def network_init(data, outputLayerNeurons = 3, hiddenLayerNeurons = 5):\n",
    "    weightsOutputLayer = generateWeights(outputLayerNeurons, hiddenLayerNeurons)\n",
    "    weightsInputLayer = generateWeights(hiddenLayerNeurons, len(data[0][:]))\n",
    "    return weightsInputLayer, weightsOutputLayer\n",
    "\n",
    "def forward_pass(weightsInputLayer,\n",
    "                 weightsOutputLayer,\n",
    "                 data, target,\n",
    "                 isL2 = True, L2rate = 0.0001, logs = False):\n",
    "    \n",
    "    H = data.dot(weightsInputLayer)\n",
    "    if logs:\n",
    "        print(\"H: \" + str(H.shape))     \n",
    "\n",
    "    A = relu(H)\n",
    "    if logs:                \n",
    "        print(\"A: \" + str(A.shape))\n",
    "          \n",
    "    H_OUTPUT = A.dot(weightsOutputLayer)\n",
    "    if logs:\n",
    "        print(\"H OUTPUT: \" + str(H_OUTPUT.shape)) \n",
    "            \n",
    "    A_OUTPUT = softmax(H_OUTPUT)\n",
    "    if logs:\n",
    "        print(\"A OUTPUT: \" + str(A_OUTPUT.shape))\n",
    "        \n",
    "    if isL2:\n",
    "        L2_ = L2(weightsOutputLayer, weightsInputLayer, L2rate)\n",
    "        \n",
    "    loss_entropy = loss(A_OUTPUT, target)\n",
    "    if logs:\n",
    "        print(\"Loss: \" + str(loss_entropy))\n",
    "        \n",
    "    return H, A, H_OUTPUT, A_OUTPUT, loss_entropy\n",
    "\n",
    "def backward_pass(H, A,\n",
    "                  H_OUTPUT,\n",
    "                  A_OUTPUT,\n",
    "                  loss,\n",
    "                   weightsInputLayer,\n",
    "                   weightsOutputLayer,\n",
    "                  data, target, alpha,\n",
    "                  opt, hyper_param,\n",
    "                  logs = False,\n",
    "                  isL2 = False,\n",
    "                  lambda_L2 = 0.001):\n",
    "    \n",
    "    REL_D = D_relu(H)\n",
    "    if logs:\n",
    "        print(\"REL_D: \" + str(REL_D.shape))\n",
    "        \n",
    "    SOFT_D = d_softmax(H_OUTPUT)\n",
    "    if logs:\n",
    "        print(\"SOFT_D: \" + str(SOFT_D.shape))\n",
    "        \n",
    "    LOSS_D = d_loss(A_OUTPUT, target)\n",
    "    if logs:\n",
    "        print(\"LOSS_D: \" + str(LOSS_D.shape))   \n",
    "        \n",
    "    g_out, g_input = copute_gradient(target,\n",
    "                          LOSS_D,\n",
    "                          A,\n",
    "                          A_OUTPUT,\n",
    "                          REL_D,\n",
    "                          SOFT_D,\n",
    "                          weightsInputLayer,\n",
    "                          weightsOutputLayer,\n",
    "                          data, alpha, logs,\n",
    "                           hyper_param, opt,\n",
    "                           isL2 = isL2,\n",
    "                           lambda_L2 = lambda_L2)\n",
    "    \n",
    "    return REL_D, SOFT_D, LOSS_D, g_out, g_input\n",
    "                \n",
    "def copute_gradient(target,\n",
    "                          loss,\n",
    "                          A,\n",
    "                          A_OUTPUT,\n",
    "                          REL_D,\n",
    "                          SOFT_D,\n",
    "                          weightsInputLayer,\n",
    "                          weightsOutputLayer,\n",
    "                          data, alpha, logs,\n",
    "                          hyper_param, \n",
    "                          opt = 'sgd',\n",
    "                          isL2 = False,\n",
    "                          lambda_L2 = 0.001):\n",
    "    \n",
    "    arrL2_IN = L2_regu(weightsInputLayer, lambda_L2)\n",
    "    arrL2_Out = L2_regu(weightsOutputLayer, lambda_L2) \n",
    "    \n",
    "    gradient = loss * SOFT_D\n",
    "    gradient_out = (A.T @ gradient) \n",
    "    if isL2:\n",
    "        gradient_out + arrL2_Out\n",
    "    \n",
    "    gradient_rel = (np.array(weightsOutputLayer).dot(gradient.T)).T * REL_D\n",
    "    gradient_input =  data.T @ gradient_rel  \n",
    "    if isL2:\n",
    "        gradient_input + arrL2_IN\n",
    "        \n",
    "    op1 = hyper_param[0]\n",
    "    op2 = hyper_param[1]\n",
    "    \n",
    "    if opt == 'momentum':\n",
    "        gradient_out, v1 =  momentum(gradient_out, alpha, op1[0], rho = 0.9)\n",
    "        gradient_input, v2 =  momentum(gradient_input, alpha, op2[0], rho = 0.9)\n",
    "        hyper_param[0][0] = v1\n",
    "        hyper_param[1][0] = v2\n",
    "        \n",
    "    elif  (opt == 'adam'):\n",
    "        gradient_out, first_moment, second_moment =  adam(gradient_out, alpha, op1[0], op1[1], b1 = 0.9, b2 = 0.99)\n",
    "        gradient_input, first_moment1, second_moment1 =  adam(gradient_input, alpha, op2[0], op2[1], b1 = 0.9, b2 = 0.99)\n",
    "        hyper_param = [[first_moment, second_moment], [first_moment1, second_moment1]]\n",
    "\n",
    "    elif  opt == 'rmspro':\n",
    "        gradient_out, ad = rmspro(gradient_out, alpha, op1[0], t = 0.5)\n",
    "        gradient_input, ad1 = rmspro(gradient_input, alpha, op2[0], t = 0.5)\n",
    "        hyper_param[0][0] = ad\n",
    "        hyper_param[1][0] = ad1\n",
    "        \n",
    "    elif  opt == 'adaGrad':\n",
    "        gradient_out, ad = adaGrad(gradient_out, alpha, op1[0], t = 0.5)\n",
    "        gradient_input, ad1 = adaGrad(gradient_input, alpha, op2[0], t = 0.5)\n",
    "        hyper_param[0][0] = ad\n",
    "        hyper_param[1][0] = ad1    \n",
    "        \n",
    "    else :\n",
    "        gradient_out = alpha * gradient_out\n",
    "        gradient_input = alpha * gradient_input\n",
    "        \n",
    "    return gradient_out, gradient_input\n",
    "###\n",
    "\n",
    "def momentum(dx, alpha = 0.001, vx = 0, rho = 0.9):\n",
    "    vx = rho * vx + dx\n",
    "    x = alpha * vx\n",
    "    return x, vx\n",
    "\n",
    "def adam(dx, alpha, first_moment = 0, second_moment = 0, b1 = 0.9, b2 = 0.99):      \n",
    "    first_moment = b1 * first_moment + (1 - b1) * dx\n",
    "    second_moment = b2 * second_moment + (1 - b2) * dx * dx\n",
    "    x = alpha * first_moment/(np.sqrt(second_moment) + 1e-7)\n",
    "    return x, first_moment, second_moment  \n",
    "\n",
    "def rmspro(dx, alpha, grad_squ = 0, t = 0.5):\n",
    "    decay_rate = alpha - t * alpha\n",
    "    grad_squ = decay_rate * grad_squ + (1 - decay_rate) * dx * dx\n",
    "    x = alpha * dx / (np.sqrt(grad_squ) + 1e-7)\n",
    "    return x, grad_squ\n",
    "\n",
    "def adaGrad(dx, alpha, grad_squ = 0, t = 0.5):\n",
    "    grad_squ += dx * dx\n",
    "    x = alpha * dx / (np.sqrt(grad_squ) + 1e-7)\n",
    "    return x, grad_squ\n",
    "\n",
    "###\n",
    "    \n",
    "def train(data, target, batchSize, batches,\n",
    "          weightsInputLayer, weightsOutputLayer, epochs, \n",
    "          logs, alpha = 0.001, opt = \"rmspro\", isL2 = False, lambda_L2 = 0.001):\n",
    "    \n",
    "    loss_w, accuracies = [], []\n",
    "    hyper_param = [[0, 0],[0, 0]]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        if logs:\n",
    "            print(\"\\n\")\n",
    "            print(\"Epoch: \" + str(epoch))\n",
    "\n",
    "        data_batch, target_batch  =  batchGenarator(data.copy(), target.copy(),\n",
    "                                                         batchSize)\n",
    "\n",
    "        H, A, H_OUTPUT, A_OUTPUT, loss_E = forward_pass(weightsInputLayer.copy(),\n",
    "                                                            weightsOutputLayer.copy(),\n",
    "                                                            data_batch.copy(),\n",
    "                                                            target_batch.copy(),                                                \n",
    "                                                            logs = logs)\n",
    "        loss_w.append((loss_E.mean()))\n",
    "\n",
    "        REL_D, SOFT_D, LOSS_D, g_out, g_input = backward_pass(H.copy(),\n",
    "                                                  A.copy(),\n",
    "                                                  H_OUTPUT.copy(),\n",
    "                                                  A_OUTPUT.copy(),\n",
    "                                                  loss_E,                                                   \n",
    "                                                  weightsInputLayer.copy(),                    \n",
    "                                                  weightsOutputLayer.copy(),\n",
    "                                                  data_batch.copy(),\n",
    "                                                  target_batch.copy(),\n",
    "                                                  alpha , opt, hyper_param, logs = logs,\n",
    "                                                  isL2 = isL2, lambda_L2 = lambda_L2)\n",
    "            \n",
    "        weightsOutputLayer -= g_out\n",
    "        if logs:\n",
    "            print(\"Weights out: \" + str(weightsOutputLayer))\n",
    "                \n",
    "        weightsInputLayer -= g_input\n",
    "        if logs:\n",
    "            print(\"Weights in: \" + str(weightsInputLayer))\n",
    "                \n",
    "        category=np.argmax(A_OUTPUT ,axis=1)\n",
    "        y_=np.argmax(target_batch,axis=1)\n",
    "        accuracy=(category==y_).mean()\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        if logs:\n",
    "            print(\"Accurancy : \" + str(accuracy))\n",
    "            \n",
    "    return weightsInputLayer, weightsOutputLayer, loss_w, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = False\n",
    "batchSize = 24\n",
    "outputLayerNeurons = 10\n",
    "hiddenLayerNeurons = 16\n",
    "\n",
    "def init(x,y):\n",
    "    layer=np.random.uniform(-1.,1.,size=(x,y))/np.sqrt(x*y)\n",
    "    return layer.astype(np.float32)\n",
    "\n",
    "np.random.seed(42)\n",
    "l1=init(28*28,hiddenLayerNeurons)\n",
    "l2=init(hiddenLayerNeurons,10)\n",
    "\n",
    "train_X, test_X , train_y, test_y = train_test_split(x, y, test_size=0.10, random_state=11)\n",
    "\n",
    "w1, w2 = network_init(train_X,\n",
    "                               outputLayerNeurons = outputLayerNeurons,\n",
    "                               hiddenLayerNeurons = hiddenLayerNeurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch: 0\n",
      "H: (24, 16)\n",
      "A: (24, 16)\n",
      "H OUTPUT: (24, 10)\n",
      "A OUTPUT: (24, 10)\n",
      "Loss: [[1.73886373e-03 9.16552028e-01 1.60529690e-03 4.78940033e-03\n",
      "  6.62794170e-04 6.82250236e-05 5.99606049e-04 8.09146041e-04\n",
      "  1.21915596e-03 5.76416224e-05]\n",
      " [1.32872848e-03 9.36619246e-01 1.59632105e-03 1.29294396e-03\n",
      "  1.17395714e-03 6.16963798e-04 1.22616775e-03 5.10740723e-04\n",
      "  5.58818797e-04 4.95150506e-04]\n",
      " [6.61887046e-04 8.14446877e-05 8.52238099e-04 9.38897336e-01\n",
      "  2.07321452e-03 1.44673678e-02 2.65256377e-04 1.40433828e-05\n",
      "  1.20427277e-04 6.17309874e-04]\n",
      " [9.61085571e-04 8.69063556e-05 8.76830448e-01 1.32162220e-04\n",
      "  1.94624712e-04 2.44038821e-03 2.60615827e-04 3.42709253e-04\n",
      "  2.09860726e-03 1.42386229e-03]\n",
      " [9.72616691e-01 3.89573335e-05 3.53142103e-03 1.12122958e-03\n",
      "  6.93433462e-04 8.05689059e-03 1.67662645e-03 5.54445217e-05\n",
      "  2.78094931e-04 8.46219313e-03]\n",
      " [6.32097805e-04 4.71029482e-05 8.69186762e-01 6.66678427e-05\n",
      "  1.59682398e-03 1.45018991e-02 8.03572838e-05 1.83893252e-04\n",
      "  1.86443321e-03 9.01879720e-04]\n",
      " [2.52419460e-04 5.98775311e-04 1.06341327e-03 6.42631160e-06\n",
      "  9.51231136e-01 1.60850601e-03 3.66039700e-04 1.03637519e-03\n",
      "  1.26433529e-03 2.77899677e-03]\n",
      " [1.00750473e-03 7.65181817e-04 9.37051784e-01 1.51670600e-04\n",
      "  8.20910483e-03 2.19800162e-04 1.05879329e-03 6.10238588e-04\n",
      "  1.65111393e-02 1.36215963e-02]\n",
      " [1.38578017e-03 4.47398113e-03 9.67610863e-01 1.09708222e-04\n",
      "  3.81330900e-04 8.47523471e-05 6.04292055e-03 8.34981205e-02\n",
      "  1.05764195e-02 1.07920686e-03]\n",
      " [6.12667932e-04 1.72933886e-04 8.69219309e-01 3.66805853e-05\n",
      "  1.40303283e-04 1.05773230e-03 4.10753041e-04 1.15895921e-03\n",
      "  3.09179986e-03 2.30180351e-03]\n",
      " [5.27819928e-04 2.82730582e-03 8.29402152e-01 6.52859764e-06\n",
      "  5.52656398e-04 2.67800168e-04 1.00874183e-03 8.94744866e-03\n",
      "  3.55933264e-03 2.66604465e-02]\n",
      " [7.00421515e-03 8.20024030e-04 4.85109228e-04 9.33499717e-01\n",
      "  5.34135943e-04 3.85241692e-04 7.80749049e-04 4.67369343e-04\n",
      "  1.67932264e-03 3.82036989e-04]\n",
      " [2.33440867e-04 8.74245046e-05 9.81734586e-01 3.92960556e-02\n",
      "  2.44620105e-02 3.39931587e-02 5.76719500e-04 3.00041870e-05\n",
      "  3.13437138e-05 1.73650053e-04]\n",
      " [1.38955168e-02 9.42231295e-01 3.34056002e-03 1.23019043e-02\n",
      "  2.63286993e-03 6.97605601e-04 8.87655341e-04 3.44645385e-05\n",
      "  1.18343218e-03 3.57571929e-04]\n",
      " [1.82691946e-04 1.52342796e-03 8.64330091e-04 9.76628840e-01\n",
      "  1.44012886e-02 5.11215524e-03 1.87078738e-03 1.67754964e-04\n",
      "  6.50337016e-05 1.13438133e-03]\n",
      " [1.41413638e-03 1.40010986e-03 2.38804471e-04 4.51863748e-04\n",
      "  2.45443698e-04 5.44568262e-04 4.98795221e-03 1.38525225e-03\n",
      "  1.32213510e-03 9.52241832e-01]\n",
      " [8.83459356e-04 2.23199031e-02 2.99693241e-04 2.41761518e-04\n",
      "  1.31733766e-03 1.38095273e-04 2.04558484e-02 1.53250710e-02\n",
      "  1.45009541e-03 9.46232238e-01]\n",
      " [5.20814788e-04 6.12920947e-04 6.03946335e-03 9.53560986e-05\n",
      "  3.87572522e-04 1.94529744e-04 8.89020905e-04 1.58006207e-03\n",
      "  2.78120632e-03 8.88380314e-01]\n",
      " [4.17688152e-03 4.52269106e-03 1.30977576e-03 1.38647848e-03\n",
      "  1.64912798e-03 1.30469417e-04 4.56301286e-03 9.47326487e-01\n",
      "  2.52955024e-03 1.90872402e-03]\n",
      " [4.42982723e-03 9.45803403e-01 1.23923529e-03 2.41450333e-02\n",
      "  8.16709928e-04 2.55880914e-04 3.51081371e-04 5.73537069e-05\n",
      "  3.36069752e-04 3.36905226e-05]\n",
      " [6.22459529e-03 1.16807188e-02 7.64836274e-04 5.80033837e-04\n",
      "  5.11085640e-03 3.73080401e-04 1.41681294e-02 9.39200265e-01\n",
      "  4.08100617e-03 3.61842152e-03]\n",
      " [6.40346400e-03 9.40671175e-01 1.48105862e-03 1.59094223e-02\n",
      "  9.88335500e-04 2.88183467e-04 2.19242585e-04 5.43689058e-05\n",
      "  4.36512778e-04 2.15993679e-05]\n",
      " [2.51726798e-03 2.35263393e-04 4.47973633e-03 2.28239917e-04\n",
      "  4.60815847e-04 2.78588413e-03 9.70331281e-01 2.56499673e-04\n",
      "  1.44203884e-03 9.86370642e-04]\n",
      " [1.07711790e-03 2.02204165e-02 8.30905896e-04 3.05614473e-04\n",
      "  7.82781018e-04 4.32149222e-05 5.35548104e-03 9.21277909e-03\n",
      "  1.22828553e-03 9.36798266e-01]]\n",
      "REL_D: (24, 16)\n",
      "SOFT_D: (24, 10)\n",
      "LOSS_D: (24, 10)\n",
      "Weights out: [[-0.03842119 -0.06311598  0.01681943  0.02846984  0.02255383  0.05702106\n",
      "  -0.00218354 -0.05782701 -0.03330904  0.02569798]\n",
      " [ 0.01785565  0.00491345  0.02894912  0.02170861  0.06027221  0.01359738\n",
      "   0.04402148 -0.03965871  0.02814701  0.0636033 ]\n",
      " [-0.01806742  0.04412976  0.03554738 -0.06964136  0.01288353 -0.05847381\n",
      "   0.07388904  0.0492377  -0.06170837 -0.05980681]\n",
      " [ 0.01493459 -0.02452842 -0.07350677  0.00659481 -0.01773169 -0.06307574\n",
      "   0.04773444  0.06559706  0.04056463  0.05097149]\n",
      " [-0.04482678 -0.0373824  -0.04608584  0.04191021  0.07082191  0.03428497\n",
      "   0.06031519  0.02193025 -0.01776253 -0.01173812]\n",
      " [-0.06715169 -0.07407338  0.03095359 -0.0097019   0.00827052  0.00910502\n",
      "  -0.0352042  -0.00382122 -0.00463173 -0.01758765]\n",
      " [ 0.05064838 -0.00754099  0.01647614  0.06249393  0.0578504   0.061651\n",
      "  -0.0363649  -0.07350463 -0.03779247 -0.03499781]\n",
      " [ 0.0647213   0.02357729 -0.06613111 -0.05764484 -0.05444663  0.02061863\n",
      "   0.03719212  0.05682858  0.06966034 -0.04712358]\n",
      " [-0.03008174 -0.04104859 -0.02230898  0.06551504  0.0118412   0.03761476\n",
      "  -0.00156846 -0.07449574 -0.06891312  0.00601519]\n",
      " [ 0.03459195 -0.04500585  0.03510481  0.04908438 -0.01395444  0.03893096\n",
      "  -0.01518049  0.02817312  0.04173542  0.07777853]\n",
      " [-0.02445322 -0.0140697  -0.05283059 -0.04679142  0.03054908  0.0658601\n",
      "  -0.01667744 -0.0506133  -0.03398715 -0.00711682]\n",
      " [-0.03311374 -0.04211856  0.0377868  -0.07785208  0.00616979  0.04637108\n",
      "  -0.03695937  0.01624831  0.02664327  0.02446084]\n",
      " [-0.00857512 -0.02417835  0.05311001  0.0408316  -0.02826473 -0.06276887\n",
      "  -0.06770433 -0.06415129  0.01310093 -0.07088865]\n",
      " [-0.02582936  0.04011759 -0.03239637  0.04150462  0.03869929 -0.04030333\n",
      "   0.0360821   0.03905803 -0.01627189 -0.04567972]\n",
      " [ 0.00335082  0.0665646   0.02232787 -0.05166736  0.02888442 -0.01154298\n",
      "   0.01438487  0.03691941  0.00231066  0.04975558]\n",
      " [ 0.03512222  0.01819276 -0.05515939  0.05312303  0.06891021 -0.05740611\n",
      "  -0.0018616  -0.03811986  0.04022257  0.03502547]]\n",
      "Weights in: [[-0.00224036  0.00804847  0.00414275 ... -0.0051368  -0.0056817\n",
      "  -0.00565349]\n",
      " [-0.00349567  0.00044208 -0.00121527 ... -0.0080991   0.00192044\n",
      "  -0.0058835 ]\n",
      " [-0.00776694  0.00801581  0.00831486 ...  0.00290218 -0.0033623\n",
      "   0.00035836]\n",
      " ...\n",
      " [ 0.00277846  0.00075172  0.00474104 ...  0.00649923 -0.00319014\n",
      "   0.00874223]\n",
      " [-0.0061127   0.00029178  0.00522937 ...  0.00163694 -0.00870254\n",
      "  -0.00890708]\n",
      " [ 0.00207319 -0.00555327 -0.00550201 ... -0.00131872  0.00796151\n",
      "  -0.00504055]]\n",
      "Accurancy : 0.08333333333333333\n",
      "\n",
      "\n",
      "Epoch: 1\n",
      "H: (24, 16)\n",
      "A: (24, 16)\n",
      "H OUTPUT: (24, 10)\n",
      "A OUTPUT: (24, 10)\n",
      "Loss: [[9.64361710e-01 1.82118735e-04 1.67405990e-03 3.77111734e-03\n",
      "  1.20902394e-03 1.54363214e-03 1.25061275e-03 3.88989833e-04\n",
      "  3.85075137e-04 6.71127193e-04]\n",
      " [2.57853713e-04 2.97555270e-03 2.82509633e-04 2.13643347e-02\n",
      "  5.31422014e-03 1.95851912e-04 8.61622648e-03 8.96988602e-01\n",
      "  2.33517658e-04 1.04373254e-04]\n",
      " [3.27219448e-04 4.54677294e-03 4.49033749e-04 1.62143636e-03\n",
      "  4.47240792e-03 3.34165575e-04 3.91050431e-03 5.23035162e-03\n",
      "  5.08186754e-04 9.69220859e-01]\n",
      " [9.74737961e-01 4.29772868e-05 6.03325857e-04 2.54421983e-03\n",
      "  1.06885311e-03 3.84895055e-03 5.28666833e-04 1.44366545e-04\n",
      "  2.79917590e-04 2.04534653e-04]\n",
      " [3.44982405e-04 1.50249096e-02 1.70839485e-03 2.42962100e-03\n",
      "  2.32622447e-02 4.18881926e-04 1.44948028e-02 8.95875588e-01\n",
      "  3.03806687e-04 3.57894600e-03]\n",
      " [1.04226395e-03 2.92387779e-03 9.30457124e-01 9.52665500e-04\n",
      "  1.01588363e-03 1.66185152e-04 1.73584928e-03 4.53526461e-03\n",
      "  1.43934476e-03 4.03897656e-04]\n",
      " [8.87474605e-01 2.11084976e-04 1.02169594e-03 2.17214525e-04\n",
      "  2.19351110e-04 1.48418905e-02 2.00407328e-03 4.34120403e-04\n",
      "  2.28578361e-03 2.45857741e-03]\n",
      " [2.92506237e-03 3.04448438e-04 9.44470106e-01 8.42849811e-04\n",
      "  1.14861765e-03 7.20523209e-03 2.15361237e-04 1.66295058e-04\n",
      "  5.94857531e-04 2.14448320e-04]\n",
      " [7.74574641e-03 9.81129127e-01 6.38918983e-03 6.28466565e-04\n",
      "  4.83943832e-04 1.79872444e-02 9.60966266e-05 3.28874993e-04\n",
      "  2.87110427e-03 2.44281932e-03]\n",
      " [1.39243554e-03 3.08258923e-04 5.13719379e-03 8.46736544e-06\n",
      "  9.66562219e-01 8.07472954e-03 3.09928441e-04 3.00257464e-03\n",
      "  7.47306657e-03 4.11626859e-03]\n",
      " [3.60357530e-03 1.32641964e-03 1.39237198e-02 1.67336634e-04\n",
      "  8.93532221e-01 1.44150886e-03 2.13691778e-03 5.61722329e-04\n",
      "  7.77770480e-03 2.86980626e-02]\n",
      " [2.04376749e-03 1.59525570e-03 5.57621853e-03 7.27360565e-05\n",
      "  9.53885501e-01 1.62701807e-03 6.33412341e-04 1.64907467e-03\n",
      "  1.98916884e-03 6.95368477e-03]\n",
      " [2.86223165e-03 1.70607139e-02 1.29244490e-03 6.56305348e-04\n",
      "  2.24136148e-03 1.77136911e-04 5.16266362e-03 8.58596280e-01\n",
      "  1.71069655e-03 1.86623176e-03]\n",
      " [1.25650318e-03 8.33871772e-03 8.95004878e-01 4.22847377e-05\n",
      "  1.57056761e-03 2.60610430e-04 2.25341401e-03 1.70577308e-02\n",
      "  2.54917575e-03 1.42347442e-02]\n",
      " [1.79546588e-03 1.11732462e-04 1.47533768e-03 3.49076523e-03\n",
      "  2.58012710e-03 9.52317844e-01 1.25395828e-04 5.75560820e-05\n",
      "  1.83610972e-03 2.02837707e-03]\n",
      " [5.20230546e-03 9.56723750e-01 5.39515850e-04 1.59857851e-02\n",
      "  8.96432506e-04 5.28355685e-04 1.05755382e-03 7.10788224e-04\n",
      "  2.05495790e-03 6.80481836e-04]\n",
      " [6.47598545e-03 2.30821505e-03 2.15519166e-03 4.08349440e-04\n",
      "  9.64628246e-01 4.97083314e-04 1.15056941e-03 1.17205545e-03\n",
      "  2.71487289e-03 2.27251351e-03]\n",
      " [1.69608132e-03 1.81249951e-04 1.71455102e-03 4.83938416e-04\n",
      "  9.67909837e-01 1.82055926e-03 2.89226116e-04 9.04732336e-04\n",
      "  2.31962679e-03 3.31766055e-04]\n",
      " [3.86932489e-03 6.57198768e-04 3.07824128e-03 6.66433196e-04\n",
      "  1.45156726e-03 1.08391211e-03 1.79193535e-03 7.61360325e-04\n",
      "  5.73242077e-03 9.28388869e-01]\n",
      " [4.54361464e-04 6.58699260e-04 1.96410021e-04 1.33780128e-03\n",
      "  1.12987534e-03 9.47686386e-01 1.57954307e-03 1.40737271e-03\n",
      "  6.88315062e-04 8.27308919e-05]\n",
      " [2.90518557e-03 4.57975993e-04 9.65243920e-01 1.23809766e-03\n",
      "  2.95512949e-04 1.38705623e-03 9.50112225e-04 1.76960310e-03\n",
      "  2.27944779e-03 6.71124823e-05]\n",
      " [1.99425754e-03 1.61962768e-02 9.41587612e-04 6.97055325e-04\n",
      "  1.26425460e-03 1.25195676e-04 3.71560312e-03 8.33414353e-01\n",
      "  1.00509008e-03 6.54854840e-04]\n",
      " [4.93916083e-04 2.11587298e-04 9.79639732e-04 7.18194156e-04\n",
      "  1.28683853e-03 1.19264617e-03 5.45169070e-04 1.27265517e-03\n",
      "  9.05478602e-01 4.40692445e-04]\n",
      " [1.51525005e-04 2.41686605e-04 7.29149958e-04 1.38589100e-02\n",
      "  6.50981858e-03 1.60924650e-03 3.00453677e-03 9.62887214e-01\n",
      "  2.34247325e-04 5.60751349e-04]]\n",
      "REL_D: (24, 16)\n",
      "SOFT_D: (24, 10)\n",
      "LOSS_D: (24, 10)\n",
      "Weights out: [[-0.0382449  -0.06315478  0.01682554  0.02837962  0.02251006  0.05697842\n",
      "  -0.00224822 -0.05758866 -0.03333015  0.02567544]\n",
      " [ 0.01784056  0.00489491  0.02892678  0.0217053   0.06035425  0.01359582\n",
      "   0.04400574 -0.03960748  0.02813701  0.06360126]\n",
      " [-0.01806757  0.04412865  0.0355473  -0.06964141  0.01288344 -0.05847382\n",
      "   0.07388876  0.04924342 -0.06170845 -0.05980686]\n",
      " [ 0.01493367 -0.02453255 -0.07348078  0.0065943  -0.01773287 -0.06307241\n",
      "   0.04773325  0.06558901  0.04056305  0.0509644 ]\n",
      " [-0.04482766 -0.03738224 -0.04608607  0.04190865  0.07082152  0.03428489\n",
      "   0.06031442  0.02193888 -0.01776296 -0.01173844]\n",
      " [-0.06713323 -0.07408289  0.03099626 -0.00971237  0.00828887  0.00914224\n",
      "  -0.03521303 -0.00383792 -0.0046491  -0.0175694 ]\n",
      " [ 0.05063438 -0.00752775  0.01650078  0.06248657  0.05785055  0.06163973\n",
      "  -0.03636663 -0.07350688 -0.03780023 -0.03498941]\n",
      " [ 0.06478307  0.0235751  -0.06612034 -0.05764673 -0.05443867  0.02060498\n",
      "   0.03718711  0.05682262  0.06964856 -0.04711177]\n",
      " [-0.0300854  -0.04104922 -0.02229688  0.06551136  0.01184051  0.03763204\n",
      "  -0.00156967 -0.07449773 -0.0688891   0.00601348]\n",
      " [ 0.03458349 -0.04498583  0.03509989  0.0490754  -0.01395534  0.03891847\n",
      "  -0.01518118  0.02817244  0.0417321   0.07777631]\n",
      " [-0.02444743 -0.01406945 -0.05281356 -0.04679569  0.03054673  0.06586746\n",
      "  -0.01668043 -0.05061648 -0.03398986 -0.00711353]\n",
      " [-0.03313924 -0.04211643  0.03781585 -0.07786602  0.00625554  0.04633475\n",
      "  -0.03696918  0.01623564  0.02670569  0.02443393]\n",
      " [-0.00857572 -0.02417839  0.05310951  0.04083044 -0.02826559 -0.06276079\n",
      "  -0.06770438 -0.06415132  0.01310031 -0.07088932]\n",
      " [-0.02582007  0.04002527 -0.03228575  0.04136444  0.03859448 -0.04028085\n",
      "   0.03597479  0.0395676  -0.0162182  -0.04564641]\n",
      " [ 0.00341551  0.06641775  0.02250115 -0.05173667  0.02898428 -0.01156113\n",
      "   0.01427887  0.0373641   0.00224698  0.04967897]\n",
      " [ 0.03511753  0.01820291 -0.05516187  0.05310858  0.06890479 -0.05737916\n",
      "  -0.00186319 -0.03811584  0.04023348  0.0350225 ]]\n",
      "Weights in: [[-0.00224036  0.00804847  0.00414275 ... -0.0051368  -0.0056817\n",
      "  -0.00565349]\n",
      " [-0.00349567  0.00044208 -0.00121527 ... -0.0080991   0.00192044\n",
      "  -0.0058835 ]\n",
      " [-0.00776694  0.00801581  0.00831486 ...  0.00290218 -0.0033623\n",
      "   0.00035836]\n",
      " ...\n",
      " [ 0.00277846  0.00075172  0.00474104 ...  0.00649923 -0.00319014\n",
      "   0.00874223]\n",
      " [-0.0061127   0.00029178  0.00522937 ...  0.00163694 -0.00870254\n",
      "  -0.00890708]\n",
      " [ 0.00207319 -0.00555327 -0.00550201 ... -0.00131872  0.00796151\n",
      "  -0.00504055]]\n",
      "Accurancy : 0.041666666666666664\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "H: (24, 16)\n",
      "A: (24, 16)\n",
      "H OUTPUT: (24, 10)\n",
      "A OUTPUT: (24, 10)\n",
      "Loss: [[2.12195794e-04 2.35578596e-04 2.75037293e-04 8.01685454e-01\n",
      "  4.63854881e-03 9.39002353e-05 1.94673059e-03 2.98570472e-04\n",
      "  4.53100957e-04 7.03931647e-05]\n",
      " [1.16337655e-04 3.29814931e-04 7.75388477e-04 8.85827998e-04\n",
      "  1.46636939e-03 4.22204627e-04 4.11607054e-03 9.38529363e-01\n",
      "  5.16378093e-04 3.67878072e-04]\n",
      " [2.72700045e-04 1.79647476e-01 3.92585840e-03 1.10110810e-05\n",
      "  1.21596827e-02 7.13083565e-05 1.60037183e-02 6.29471499e-01\n",
      "  9.70066620e-04 1.48594164e-02]\n",
      " [1.14578436e-03 3.18195218e-03 3.05722613e-04 5.69913885e-04\n",
      "  1.84745955e-03 5.42322276e-05 3.93427476e-03 1.11515782e-03\n",
      "  2.05050423e-03 9.35492169e-01]\n",
      " [1.51921838e-03 1.24822055e-03 6.30841436e-03 9.89183890e-01\n",
      "  2.30603808e-03 3.82056429e-03 1.09062503e-03 1.88279802e-04\n",
      "  4.08632123e-04 5.79970521e-03]\n",
      " [9.32764875e-03 9.34294371e-01 2.49757693e-04 1.56717691e-02\n",
      "  2.53779894e-03 8.62889878e-05 1.85083259e-03 7.73771192e-05\n",
      "  2.00805417e-03 1.94995883e-04]\n",
      " [2.88102867e-03 9.09053375e-01 1.35304684e-04 6.26311183e-03\n",
      "  8.13041129e-04 3.20697722e-05 4.09788282e-03 7.34187515e-04\n",
      "  1.49817582e-03 9.19334745e-05]\n",
      " [7.82487303e-04 3.99562655e-04 2.43284924e-03 2.20181663e-05\n",
      "  9.71457500e-01 4.29464026e-04 1.62692162e-03 2.11772222e-03\n",
      "  3.84099853e-03 4.65453503e-03]\n",
      " [3.64852501e-04 4.95406612e-03 1.07283073e-03 5.52475348e-05\n",
      "  1.03362346e-03 8.31900004e-05 8.83100495e-01 1.55841057e-02\n",
      "  2.72896078e-03 4.69642705e-04]\n",
      " [1.06689687e-04 2.56774706e-04 6.28039437e-03 5.88816709e-06\n",
      "  8.67656687e-01 6.53670773e-03 1.55265835e-03 7.90094742e-04\n",
      "  2.11057789e-03 1.63656827e-02]\n",
      " [1.38287890e-02 9.37736473e-01 2.70196222e-03 2.71510196e-03\n",
      "  2.02729702e-03 7.41983906e-04 3.35580350e-03 6.88180911e-05\n",
      "  2.11887965e-03 2.06649963e-03]\n",
      " [1.56135882e-03 2.51971913e-04 1.55788913e-03 5.98991277e-04\n",
      "  1.24199801e-03 1.33436303e-03 1.92848298e-03 1.66056997e-04\n",
      "  9.22888344e-01 7.29401786e-04]\n",
      " [9.32687938e-04 9.21905342e-05 5.23904140e-04 3.80296376e-03\n",
      "  2.81680088e-04 9.31879031e-01 1.29030777e-03 1.50520874e-04\n",
      "  5.09402339e-04 6.23376704e-04]\n",
      " [6.77516916e-04 4.91512970e-04 8.41578571e-01 3.50901701e-06\n",
      "  2.19082602e-04 8.56398440e-04 4.79409038e-04 3.61287582e-03\n",
      "  7.74971585e-03 4.24124686e-03]\n",
      " [5.42404322e-04 2.58544789e-04 3.90125545e-04 5.91274911e-03\n",
      "  4.59009738e-04 9.61439696e-01 1.82449541e-03 9.74453146e-05\n",
      "  1.46112790e-04 2.31754059e-04]\n",
      " [2.43429991e-04 2.10958173e-03 9.11700010e-01 1.61777907e-05\n",
      "  9.52291235e-04 1.93277484e-04 1.81644340e-03 1.64008341e-02\n",
      "  4.27680197e-03 7.40143768e-04]\n",
      " [6.12631514e-04 1.64226535e-04 2.18334445e-03 1.37010307e-04\n",
      "  1.28238432e-04 9.65725823e-01 9.52863645e-04 6.85349671e-04\n",
      "  2.04737026e-03 7.56739081e-04]\n",
      " [1.67597732e-02 9.31714160e-01 2.16395163e-04 3.65214305e-02\n",
      "  4.66459453e-03 2.06511463e-04 1.29433102e-03 4.74653299e-05\n",
      "  7.83545902e-04 6.66045032e-05]\n",
      " [1.72927862e-04 1.06755660e-04 3.80487792e-03 3.81769606e-05\n",
      "  3.89947025e-04 1.17731037e-03 9.51401057e-01 9.12953781e-04\n",
      "  1.77516355e-03 1.64914910e-03]\n",
      " [4.32537016e-04 3.55613183e-04 9.20956469e-01 2.42566378e-04\n",
      "  2.05826967e-04 1.01486972e-04 1.23468000e-03 1.43128566e-03\n",
      "  1.68723580e-03 3.62265219e-04]\n",
      " [1.40227302e-03 3.51081772e-05 5.14698310e-04 9.26159758e-01\n",
      "  2.02121090e-03 2.09758968e-02 1.99461887e-04 4.55465798e-06\n",
      "  1.18979270e-04 1.20373255e-04]\n",
      " [1.45899063e-02 8.29020801e-05 7.01785134e-04 8.88709863e-01\n",
      "  1.03471150e-02 8.10374500e-02 6.72062577e-05 1.74567888e-06\n",
      "  1.23437123e-04 4.60667283e-05]\n",
      " [4.16986737e-04 6.87754652e-04 8.02108851e-01 9.67840145e-08\n",
      "  3.90958840e-04 2.05434201e-03 3.72453870e-04 1.54775885e-02\n",
      "  2.02010124e-02 3.00718089e-02]\n",
      " [3.39461933e-03 2.74884914e-05 8.02380798e-04 8.58800043e-01\n",
      "  2.92555197e-03 2.97691918e-03 8.51433167e-05 5.97031174e-06\n",
      "  4.67787201e-04 7.63086654e-05]]\n",
      "REL_D: (24, 16)\n",
      "SOFT_D: (24, 10)\n",
      "LOSS_D: (24, 10)\n",
      "Weights out: [[-0.03825408 -0.06328125  0.01679747  0.02847487  0.02258496  0.05695254\n",
      "  -0.00226643 -0.05739425 -0.03334218  0.02564319]\n",
      " [ 0.01781531  0.00495685  0.02891813  0.02168912  0.06038466  0.01358988\n",
      "   0.04399762 -0.03960824  0.02816568  0.06358904]\n",
      " [-0.01806794  0.04412834  0.03554583 -0.06964005  0.01288288 -0.05847473\n",
      "   0.0738885   0.04924337 -0.06170855 -0.05980822]\n",
      " [ 0.0149333  -0.02453289 -0.07345483  0.00659429 -0.01772861 -0.06307317\n",
      "   0.04773264  0.06558406  0.04055639  0.05095512]\n",
      " [-0.0448277  -0.0373823  -0.04608707  0.04190874  0.0708307   0.0342839\n",
      "   0.06031417  0.02193876 -0.01776328 -0.01174074]\n",
      " [-0.06714327 -0.07408522  0.03106022 -0.0094447   0.00828489  0.00915166\n",
      "  -0.03521204 -0.00384739 -0.00463906 -0.01757981]\n",
      " [ 0.05053584 -0.00739696  0.01648602  0.06281548  0.05779488  0.06143394\n",
      "  -0.03638045 -0.07350796 -0.03778116 -0.03499804]\n",
      " [ 0.06478187  0.0235746  -0.06610136 -0.05762927 -0.05443529  0.02060706\n",
      "   0.03718508  0.05681826  0.06965845 -0.04711999]\n",
      " [-0.03008964 -0.04104746 -0.02230132  0.06554244  0.01183565  0.03769063\n",
      "  -0.00156683 -0.07449248 -0.06886127  0.00601096]\n",
      " [ 0.03458    -0.04497732  0.03509917  0.04907105 -0.01395611  0.03893787\n",
      "  -0.01518265  0.02817233  0.04173125  0.07777562]\n",
      " [-0.02447163 -0.01406406 -0.05279445 -0.04663867  0.03056336  0.06576763\n",
      "  -0.0166838  -0.0506218  -0.03399854 -0.00712758]\n",
      " [-0.03316209 -0.04223589  0.03831046 -0.07781509  0.00637931  0.04626553\n",
      "  -0.03687106  0.01628468  0.02663912  0.02429489]\n",
      " [-0.00857759 -0.02417145  0.05310945  0.04082739 -0.02826613 -0.06276082\n",
      "  -0.06770477 -0.06415133  0.01309988 -0.07088937]\n",
      " [-0.02587531  0.03991952 -0.03218354  0.04150677  0.03859532 -0.0402732\n",
      "   0.03604137  0.03988986 -0.01622384 -0.04565814]\n",
      " [ 0.00338946  0.0659174   0.02288825 -0.05165209  0.02906915 -0.01156537\n",
      "   0.01428847  0.03792513  0.00217939  0.04951863]\n",
      " [ 0.03509197  0.01827729 -0.0551634   0.05318039  0.06889106 -0.05739007\n",
      "  -0.00187219 -0.03811741  0.0402282   0.03504622]]\n",
      "Weights in: [[-0.00224036  0.00804847  0.00414275 ... -0.0051368  -0.0056817\n",
      "  -0.00565349]\n",
      " [-0.00349567  0.00044208 -0.00121527 ... -0.0080991   0.00192044\n",
      "  -0.0058835 ]\n",
      " [-0.00776694  0.00801581  0.00831486 ...  0.00290218 -0.0033623\n",
      "   0.00035836]\n",
      " ...\n",
      " [ 0.00277846  0.00075172  0.00474104 ...  0.00649923 -0.00319014\n",
      "   0.00874223]\n",
      " [-0.0061127   0.00029178  0.00522937 ...  0.00163694 -0.00870254\n",
      "  -0.00890708]\n",
      " [ 0.00207319 -0.00555327 -0.00550201 ... -0.00131872  0.00796151\n",
      "  -0.00504055]]\n",
      "Accurancy : 0.08333333333333333\n",
      "\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H: (24, 16)\n",
      "A: (24, 16)\n",
      "H OUTPUT: (24, 10)\n",
      "A OUTPUT: (24, 10)\n",
      "Loss: [[9.55904395e-01 1.32438293e-03 1.24587927e-04 1.28906157e-03\n",
      "  5.93215332e-04 1.68608710e-04 3.83074893e-03 2.74656534e-03\n",
      "  8.24530250e-04 4.86222044e-05]\n",
      " [1.36829904e-03 3.36946859e-04 5.03466738e-03 9.92724924e-04\n",
      "  1.54477681e-03 1.22052688e-03 3.81772408e-04 2.22957649e-04\n",
      "  9.52547724e-01 6.56377874e-04]\n",
      " [7.31170378e-04 9.62534044e-01 5.68825208e-04 9.77720400e-04\n",
      "  5.07021688e-04 4.54403583e-04 1.09987412e-03 2.56063503e-03\n",
      "  2.30605653e-03 6.64417393e-05]\n",
      " [2.41900613e-03 9.84281703e-01 1.44499022e-03 8.56315288e-03\n",
      "  4.23789590e-04 1.86797784e-03 1.28731439e-03 5.63886529e-04\n",
      "  4.04010765e-03 8.13921301e-04]\n",
      " [2.89495211e-03 2.31875219e-03 9.73700983e-01 2.03320941e-03\n",
      "  3.21200703e-03 3.87621180e-04 1.37679195e-03 5.55790554e-04\n",
      "  1.10592180e-03 1.33081107e-04]\n",
      " [6.55074761e-04 1.28817439e-04 3.77098097e-03 2.83894759e-05\n",
      "  2.11477386e-04 2.33166220e-03 9.64315703e-01 1.87921782e-03\n",
      "  5.90441858e-03 1.15348156e-03]\n",
      " [8.12733122e-03 2.62173189e-04 2.87643416e-04 1.19000059e-02\n",
      "  7.95268480e-03 3.42590877e-04 2.95934066e-04 4.93121509e-05\n",
      "  8.81533522e-01 4.16448147e-04]\n",
      " [3.85601888e-03 1.44058481e-02 2.25737277e-03 8.35083900e-05\n",
      "  3.29329958e-04 9.83820460e-01 9.85740694e-03 4.38321108e-03\n",
      "  5.94107908e-04 6.68830695e-04]\n",
      " [1.08195202e-03 1.95216684e-04 2.31289393e-04 1.26024882e-03\n",
      "  3.54506893e-04 1.39702065e-03 9.26413375e-01 1.88702800e-04\n",
      "  8.60127911e-04 1.96136509e-04]\n",
      " [5.96777248e-04 6.69820505e-02 1.72705947e-04 4.77557594e-03\n",
      "  1.85955107e-02 2.89482348e-05 4.04772390e-02 8.01853660e-01\n",
      "  4.61492892e-04 5.97682171e-04]\n",
      " [1.27490445e-03 9.74959940e-04 5.90266419e-04 2.38603217e-03\n",
      "  9.62234735e-01 2.07820449e-04 2.84625533e-03 9.24081466e-04\n",
      "  8.71077274e-04 2.95928925e-04]\n",
      " [5.14942745e-04 6.44732214e-04 5.27235041e-03 5.45897569e-05\n",
      "  5.05291134e-04 6.27591930e-04 7.36183387e-04 9.06378979e-01\n",
      "  2.15999206e-03 2.51443071e-03]\n",
      " [3.67935634e-02 9.59043880e-01 3.29587060e-04 2.60580789e-02\n",
      "  7.90870379e-04 1.76935499e-03 1.57674555e-03 3.88947768e-05\n",
      "  1.28039585e-03 6.56710748e-05]\n",
      " [4.47840751e-04 2.29120620e-03 9.08054208e-01 2.11326415e-05\n",
      "  1.03349933e-03 5.31425802e-04 1.14488853e-03 1.42094229e-02\n",
      "  4.34641174e-03 9.77362729e-04]\n",
      " [6.18804469e-04 3.38471364e-03 1.31266222e-03 1.50978431e-04\n",
      "  2.86182867e-03 3.06358879e-04 2.40789103e-03 8.72443106e-01\n",
      "  2.36820778e-03 2.11534615e-03]\n",
      " [1.41279831e-04 5.44530952e-03 8.59137822e-01 1.47980793e-06\n",
      "  4.08388545e-03 9.53398913e-04 7.30599715e-04 1.71385057e-02\n",
      "  2.34241071e-03 5.90141437e-03]\n",
      " [8.98305270e-01 2.61231446e-05 9.03969519e-04 1.13260076e-03\n",
      "  1.25811883e-04 1.83315805e-03 3.31422863e-04 6.04726895e-05\n",
      "  3.53803706e-03 1.08740730e-03]\n",
      " [1.07005440e-03 2.47144945e-05 7.11077785e-04 1.02046448e-03\n",
      "  7.75044702e-04 2.62981574e-02 9.68718787e-01 2.23002655e-05\n",
      "  4.14840667e-04 2.51094912e-04]\n",
      " [3.73159968e-03 1.63524816e-02 6.93444454e-04 5.04491176e-04\n",
      "  4.97521866e-04 8.01787175e-05 5.10638750e-03 4.34501371e-03\n",
      "  1.43459780e-03 9.41727747e-01]\n",
      " [6.90872178e-04 8.57776443e-05 9.65846488e-01 1.72661904e-02\n",
      "  3.01039821e-03 6.92615334e-04 3.52762916e-04 7.42916790e-05\n",
      "  3.44133036e-04 2.30187726e-05]\n",
      " [3.51739491e-04 7.18717022e-04 5.19122108e-03 2.39832912e-05\n",
      "  5.78831665e-04 5.17118236e-04 9.52158324e-01 6.51555617e-03\n",
      "  3.79283778e-03 1.45889857e-03]\n",
      " [3.57971214e-04 3.02736400e-05 4.19828970e-03 2.86316349e-04\n",
      "  1.26288794e-02 1.57185552e-02 6.32586271e-04 3.97731426e-05\n",
      "  9.25326870e-01 6.82305676e-02]\n",
      " [3.94511716e-04 6.31534446e-05 1.08290392e-02 7.46667975e-04\n",
      "  5.89239729e-03 6.81755363e-01 2.59689283e-04 1.23590962e-05\n",
      "  1.02594201e-04 1.90462699e-02]\n",
      " [1.41004063e-03 2.83598960e-05 5.75760441e-03 9.71405944e-04\n",
      "  1.17910675e-04 9.32132537e-01 3.77278330e-04 4.68362234e-04\n",
      "  4.69134927e-03 2.53743883e-03]]\n",
      "REL_D: (24, 16)\n",
      "SOFT_D: (24, 10)\n",
      "LOSS_D: (24, 10)\n",
      "Weights out: [[-0.03822065 -0.06334386  0.01675594  0.02845602  0.02252918  0.05711516\n",
      "  -0.00227024 -0.05722827 -0.03323104  0.02546031]\n",
      " [ 0.01778968  0.00497655  0.0289151   0.02166655  0.06038328  0.01359907\n",
      "   0.04400259 -0.03960878  0.02816411  0.06358761]\n",
      " [-0.0180711   0.04411726  0.03554395 -0.06964012  0.0128826  -0.05846774\n",
      "   0.07388073  0.0492398  -0.06170906 -0.05980879]\n",
      " [ 0.0149333  -0.02453289 -0.07345483  0.00659429 -0.01772861 -0.06307317\n",
      "   0.04773264  0.06558406  0.04055639  0.05095512]\n",
      " [-0.04482817 -0.03739621 -0.04608981  0.04190726  0.0708196   0.03427809\n",
      "   0.06030473  0.02196217 -0.01774299 -0.01177074]\n",
      " [-0.06712793 -0.07409552  0.03112807 -0.00948564  0.00826387  0.00931218\n",
      "  -0.03519837 -0.00383093 -0.00457541 -0.01763028]\n",
      " [ 0.05047826 -0.00736382  0.01649805  0.06274801  0.05776944  0.06151982\n",
      "  -0.03637298 -0.07350969 -0.03769045 -0.03502728]\n",
      " [ 0.06478173  0.02358136 -0.06610155 -0.05763807 -0.05443588  0.02060634\n",
      "   0.03718267  0.05681691  0.06965758 -0.04712004]\n",
      " [-0.03008362 -0.04104755 -0.02231237  0.06553776  0.01182717  0.03785102\n",
      "  -0.00156861 -0.07449348 -0.06885788  0.00598872]\n",
      " [ 0.03457673 -0.04496896  0.03509379  0.04906285 -0.01395663  0.03896044\n",
      "  -0.01518417  0.02817133  0.04172421  0.07777304]\n",
      " [-0.02446872 -0.01406788 -0.05272114 -0.04665453  0.03055518  0.06574452\n",
      "  -0.01664506 -0.05063736 -0.03400332 -0.00713268]\n",
      " [-0.03313481 -0.04221701  0.03851607 -0.07784602  0.00632455  0.04631728\n",
      "  -0.03675764  0.0163412   0.0267017   0.02416981]\n",
      " [-0.00857759 -0.02417145  0.05310945  0.04082739 -0.02826613 -0.06276082\n",
      "  -0.06770477 -0.06415133  0.01309988 -0.07088937]\n",
      " [-0.02589888  0.03975563 -0.03194102  0.04138834  0.03851781 -0.04029175\n",
      "   0.03598985  0.04027961 -0.01619624 -0.04564601]\n",
      " [ 0.00337779  0.06563576  0.02317581 -0.05170261  0.02893961 -0.01113987\n",
      "   0.01420505  0.03834587  0.00232123  0.04933155]\n",
      " [ 0.03510313  0.01825398 -0.05515849  0.05315021  0.06885301 -0.0573728\n",
      "  -0.00188947 -0.03805771  0.04035801  0.03498016]]\n",
      "Weights in: [[-0.00224036  0.00804847  0.00414275 ... -0.0051368  -0.0056817\n",
      "  -0.00565349]\n",
      " [-0.00349567  0.00044208 -0.00121527 ... -0.0080991   0.00192044\n",
      "  -0.0058835 ]\n",
      " [-0.00776694  0.00801581  0.00831486 ...  0.00290218 -0.0033623\n",
      "   0.00035836]\n",
      " ...\n",
      " [ 0.00277846  0.00075172  0.00474104 ...  0.00649923 -0.00319014\n",
      "   0.00874223]\n",
      " [-0.0061127   0.00029178  0.00522937 ...  0.00163694 -0.00870254\n",
      "  -0.00890708]\n",
      " [ 0.00207319 -0.00555327 -0.00550201 ... -0.00131872  0.00796151\n",
      "  -0.00504055]]\n",
      "Accurancy : 0.125\n",
      "\n",
      "\n",
      "Epoch: 4\n",
      "H: (24, 16)\n",
      "A: (24, 16)\n",
      "H OUTPUT: (24, 10)\n",
      "A OUTPUT: (24, 10)\n",
      "Loss: [[5.54054813e-03 9.41384729e-01 2.14480765e-04 1.72547838e-02\n",
      "  7.23698045e-04 2.78977185e-04 5.12747067e-04 8.51917353e-05\n",
      "  6.86773270e-04 2.82745144e-05]\n",
      " [1.02759926e-03 5.72753479e-03 4.42247244e-04 2.62200951e-03\n",
      "  1.83082806e-03 4.12498946e-04 5.39862279e-03 4.00360630e-03\n",
      "  9.59245476e-01 1.27182462e-04]\n",
      " [1.35754724e-04 1.24189180e-03 6.17568868e-03 2.15964409e-04\n",
      "  4.38303155e-03 6.63196108e-03 5.36268098e-03 9.43051616e-01\n",
      "  1.70875132e-04 2.48540262e-02]\n",
      " [6.04906455e-04 3.28471383e-04 1.56356160e-03 2.48536268e-04\n",
      "  1.73752288e-04 9.48972221e-01 1.16900841e-03 2.45823234e-03\n",
      "  1.46240194e-03 6.24039443e-04]\n",
      " [1.04951891e-02 4.44820208e-03 1.70802770e-03 1.34733593e-03\n",
      "  1.18190787e-03 1.71308185e-03 8.62246769e-04 6.07904852e-04\n",
      "  9.55626927e-01 3.06185330e-04]\n",
      " [4.60894800e-04 6.34781348e-04 6.48052249e-04 5.17199042e-03\n",
      "  4.44930360e-03 9.35108183e-01 1.63966705e-03 3.60535980e-04\n",
      "  2.71053045e-04 5.32478964e-04]\n",
      " [8.60515832e-04 1.51295553e-03 9.39171808e-01 1.12341288e-04\n",
      "  3.77311762e-04 5.27496143e-04 1.96019871e-03 8.62739398e-03\n",
      "  3.82116853e-03 5.01593579e-04]\n",
      " [3.33785481e-03 8.96802358e-04 7.12825349e-04 2.67559950e-03\n",
      "  1.40713228e-02 9.73167171e-01 3.70999962e-04 1.34942572e-04\n",
      "  2.98391493e-03 4.57808114e-03]\n",
      " [1.68648950e-04 2.55372437e-05 1.58212548e-03 3.95918717e-04\n",
      "  1.98453301e-04 1.33996978e-02 9.60063661e-01 1.84450289e-04\n",
      "  3.63817615e-04 1.12346525e-03]\n",
      " [5.01888838e-03 1.22845403e-02 9.03057054e-01 7.24004120e-05\n",
      "  1.55864510e-03 1.43013038e-03 2.46610923e-03 1.11656012e-03\n",
      "  1.18435812e-03 6.68022992e-03]\n",
      " [2.86557448e-03 1.75391571e-04 9.47218511e-01 6.19652253e-03\n",
      "  4.48845592e-04 6.82099643e-04 3.73115097e-04 1.66859576e-04\n",
      "  9.61597070e-04 1.05661000e-04]\n",
      " [1.74663996e-03 3.57825576e-03 9.67372915e-04 1.12285734e-04\n",
      "  2.12403358e-03 9.01898849e-01 8.81547844e-04 1.03757990e-03\n",
      "  7.02998513e-04 1.50308904e-03]\n",
      " [2.20229521e-03 1.16085517e-03 1.88360622e-03 7.89344845e-05\n",
      "  9.80482069e-01 8.05716747e-04 9.78549590e-04 2.84419001e-03\n",
      "  2.62181163e-03 1.36491396e-03]\n",
      " [5.15874977e-04 7.76423142e-04 5.72171528e-03 2.43297839e-05\n",
      "  9.71693295e-01 7.89607928e-04 5.95707176e-04 5.30658811e-03\n",
      "  2.36783747e-03 2.26896116e-03]\n",
      " [9.61230263e-01 8.16370073e-04 1.94495274e-03 3.15222065e-04\n",
      "  3.02083376e-04 3.57746879e-04 1.47618592e-03 3.31633014e-03\n",
      "  9.14454219e-04 6.22199102e-04]\n",
      " [2.71960590e-03 3.26211918e-03 2.18170620e-03 4.44993799e-04\n",
      "  6.78433830e-04 3.65289742e-04 5.90408550e-03 9.21828253e-01\n",
      "  2.83253993e-03 3.23860097e-03]\n",
      " [5.72269847e-03 2.82295795e-02 1.62367660e-04 9.25034217e-01\n",
      "  3.95145552e-02 1.20047926e-04 5.60526124e-03 4.30705559e-03\n",
      "  6.78419248e-03 7.77688334e-04]\n",
      " [5.92065473e-04 8.25271621e-04 6.65518284e-04 1.89339599e-04\n",
      "  3.32379982e-04 1.23819522e-03 5.01643883e-03 8.63310617e-01\n",
      "  1.47961288e-03 8.78582822e-04]\n",
      " [4.43781556e-05 8.94673101e-06 4.45338713e-02 2.85102697e-06\n",
      "  4.68204273e-04 6.22162022e-02 1.07943911e-04 9.22405957e-01\n",
      "  3.41069963e-03 1.54454187e-02]\n",
      " [9.07175900e-01 2.12815608e-03 6.07996624e-04 9.35773211e-05\n",
      "  8.61371742e-05 4.04052100e-04 2.70029774e-03 9.40159449e-03\n",
      "  3.73395304e-03 3.48045236e-04]\n",
      " [1.04677051e-03 1.84198304e-04 1.60316972e-04 2.49548420e-04\n",
      "  5.70701946e-03 5.23652917e-04 9.72866198e-01 1.56761514e-04\n",
      "  7.42648544e-03 2.63733475e-03]\n",
      " [2.49176244e-03 5.65188147e-04 1.25086624e-04 4.46897409e-01\n",
      "  6.15956807e-03 1.24315529e-04 4.48500697e-03 2.94867379e-04\n",
      "  2.32543344e-03 5.32189934e-04]\n",
      " [9.13352213e-01 3.89526704e-04 9.65997698e-04 5.17493783e-04\n",
      "  1.09718280e-04 2.30126306e-03 2.18348753e-03 5.46572259e-04\n",
      "  9.95306718e-04 1.26656055e-03]\n",
      " [2.02100982e-03 1.67679594e-03 9.30296349e-01 1.50405216e-04\n",
      "  1.21664054e-04 5.12866799e-04 1.43438774e-03 3.48250916e-03\n",
      "  2.10891885e-03 8.37181840e-04]]\n",
      "REL_D: (24, 16)\n",
      "SOFT_D: (24, 10)\n",
      "LOSS_D: (24, 10)\n",
      "Weights out: [[-0.03815646 -0.06335845  0.01667387  0.02856214  0.02249383  0.05705318\n",
      "  -0.0022951  -0.05698489 -0.0332305   0.0253598 ]\n",
      " [ 0.01777873  0.00495148  0.0289505   0.02177857  0.06036016  0.01359742\n",
      "   0.04398855 -0.03957016  0.02815447  0.06357883]\n",
      " [-0.01807111  0.04411725  0.0355439  -0.06964012  0.01288273 -0.05846775\n",
      "   0.07388072  0.04923975 -0.06170908 -0.05980881]\n",
      " [ 0.0149332  -0.02453303 -0.07345495  0.00659426 -0.01772867 -0.06307338\n",
      "   0.04773183  0.06559475  0.04055614  0.05095497]\n",
      " [-0.04482839 -0.0373964  -0.04609464  0.04190716  0.07081923  0.03428113\n",
      "   0.06030401  0.02196717 -0.01774386 -0.0117738 ]\n",
      " [-0.06707753 -0.07410652  0.03112277 -0.0094329   0.00824558  0.00933552\n",
      "  -0.03519889 -0.00376331 -0.0046029  -0.01765922]\n",
      " [ 0.05044262 -0.00737836  0.01654233  0.06280271  0.05771683  0.06158146\n",
      "  -0.03638525 -0.07351884 -0.03765782 -0.03503801]\n",
      " [ 0.06482632  0.02356768 -0.06609868 -0.05762301 -0.05445063  0.02060418\n",
      "   0.03717314  0.05685392  0.06965254 -0.04712181]\n",
      " [-0.03008466 -0.04104903 -0.02231525  0.06553446  0.01182389  0.03786589\n",
      "  -0.00154157 -0.07449427 -0.06885877  0.00598638]\n",
      " [ 0.03457563 -0.04496922  0.03508852  0.04913125 -0.01395931  0.03895345\n",
      "  -0.01518612  0.02817662  0.04172271  0.07777079]\n",
      " [-0.0244763  -0.01406137 -0.05269498 -0.04666314  0.03054797  0.06577065\n",
      "  -0.0166348  -0.05063889 -0.0340112  -0.00713958]\n",
      " [-0.03315653 -0.04226877  0.03845933 -0.07779841  0.00627762  0.04620825\n",
      "  -0.03672074  0.01646176  0.02667438  0.02410068]\n",
      " [-0.00858111 -0.02415342  0.0531113   0.04081729 -0.02826662 -0.06276105\n",
      "  -0.06770512 -0.0641514   0.01309938 -0.0708894 ]\n",
      " [-0.02590658  0.03969602 -0.03189102  0.04174787  0.03839969 -0.04021914\n",
      "   0.03594454  0.0403544  -0.01616962 -0.04568025]\n",
      " [ 0.00345999  0.0655117   0.02325555 -0.0516569   0.02884666 -0.01105716\n",
      "   0.01414142  0.03861671  0.00231806  0.04918036]\n",
      " [ 0.03507738  0.01822988 -0.05514382  0.05339119  0.0687548  -0.0573144\n",
      "  -0.00187701 -0.03806668  0.04032278  0.03496289]]\n",
      "Weights in: [[-0.00224036  0.00804847  0.00414275 ... -0.0051368  -0.0056817\n",
      "  -0.00565349]\n",
      " [-0.00349567  0.00044208 -0.00121527 ... -0.0080991   0.00192044\n",
      "  -0.0058835 ]\n",
      " [-0.00776694  0.00801581  0.00831486 ...  0.00290218 -0.0033623\n",
      "   0.00035836]\n",
      " ...\n",
      " [ 0.00277846  0.00075172  0.00474104 ...  0.00649923 -0.00319014\n",
      "   0.00874223]\n",
      " [-0.0061127   0.00029178  0.00522937 ...  0.00163694 -0.00870254\n",
      "  -0.00890708]\n",
      " [ 0.00207319 -0.00555327 -0.00550201 ... -0.00131872  0.00796151\n",
      "  -0.00504055]]\n",
      "Accurancy : 0.08333333333333333\n",
      "\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H: (24, 16)\n",
      "A: (24, 16)\n",
      "H OUTPUT: (24, 10)\n",
      "A OUTPUT: (24, 10)\n",
      "Loss: [[1.31292336e-03 2.56072940e-04 8.31879386e-01 1.34254686e-05\n",
      "  1.28324239e-03 5.94774806e-03 3.29601289e-04 7.35029997e-04\n",
      "  8.73640839e-03 4.83266723e-03]\n",
      " [7.19924050e-05 1.32983234e-03 5.58920058e-03 1.91863722e-06\n",
      "  8.84181796e-04 1.88337068e-04 8.03115680e-04 4.51460304e-02\n",
      "  6.22360976e-03 8.32361009e-01]\n",
      " [9.11560549e-01 1.12977008e-04 6.20604815e-05 2.17068458e-04\n",
      "  4.18142371e-05 3.55036676e-03 7.27716236e-03 9.85583547e-04\n",
      "  5.84834102e-03 1.96438970e-04]\n",
      " [1.94855662e-03 6.67408818e-03 2.13660454e-03 1.65501988e-04\n",
      "  2.88541517e-03 6.56378480e-04 1.19235648e-03 1.45888036e-03\n",
      "  9.43874687e-01 1.46729367e-03]\n",
      " [7.62861956e-04 2.86596933e-03 4.54630707e-04 1.02738315e-04\n",
      "  9.56296610e-01 1.75324950e-04 9.56340299e-03 5.71370622e-03\n",
      "  1.23704622e-03 8.03968621e-04]\n",
      " [3.24500825e-04 1.94886074e-03 1.42557434e-03 6.43382265e-05\n",
      "  9.57446757e-01 1.72061627e-04 1.98087072e-03 4.62327834e-03\n",
      "  1.78239475e-03 2.09222319e-03]\n",
      " [1.66764978e-03 1.50124846e-04 3.50288597e-04 7.50915552e-01\n",
      "  1.42555755e-03 1.42665219e-03 5.25313588e-04 8.31581620e-05\n",
      "  2.78172803e-04 2.11724193e-05]\n",
      " [2.28010527e-03 1.01426996e-04 5.80396433e-04 1.25142059e-02\n",
      "  2.07099215e-02 8.48809377e-01 1.08596735e-03 8.23337975e-06\n",
      "  9.65615701e-04 1.89626337e-03]\n",
      " [9.58857184e-01 1.32895320e-04 1.39907274e-04 1.62354322e-03\n",
      "  3.08622200e-04 1.70219894e-03 4.08721460e-03 2.29386942e-04\n",
      "  8.23000568e-04 4.86028551e-04]\n",
      " [9.67522085e-01 6.55574863e-04 8.66451214e-04 1.91340126e-04\n",
      "  3.75079372e-04 2.57765770e-04 1.92438576e-03 2.21398185e-03\n",
      "  1.44192397e-03 9.51622529e-04]\n",
      " [7.49526104e-03 4.00900823e-04 2.93708391e-03 1.84969574e-04\n",
      "  1.16909215e-03 4.10190452e-03 9.55340797e-01 1.33728390e-04\n",
      "  4.57324399e-03 2.51037931e-03]\n",
      " [2.07453914e-04 2.42084845e-04 3.92189237e-04 4.63071782e-03\n",
      "  1.94354467e-03 9.72913004e-01 1.14514684e-03 6.47570620e-04\n",
      "  6.19851603e-04 7.42452194e-05]\n",
      " [5.65918771e-03 9.35400162e-01 2.76644668e-04 1.91063983e-03\n",
      "  1.47239604e-04 2.20361098e-04 1.78855934e-03 9.08344332e-04\n",
      "  2.62109591e-03 5.34919760e-04]\n",
      " [9.63076274e-01 1.11242983e-04 4.58466035e-04 7.58779837e-04\n",
      "  2.24549562e-04 7.53382894e-04 1.12658660e-03 2.75972830e-04\n",
      "  7.99217527e-04 4.32484108e-04]\n",
      " [2.20562863e-03 5.31073175e-03 4.27493887e-04 2.89344093e-03\n",
      "  7.07374766e-03 6.72683514e-04 1.89376510e-03 9.37597318e-01\n",
      "  4.37531370e-04 8.47007089e-05]\n",
      " [5.87783110e-04 9.24487220e-04 4.73648472e-03 4.00089204e-06\n",
      "  9.65015765e-01 1.86720414e-03 7.62763405e-04 2.87372465e-03\n",
      "  4.61037501e-03 1.87555826e-02]\n",
      " [5.06134129e-03 1.54754304e-03 3.60366149e-04 2.12288910e-03\n",
      "  1.44660316e-04 1.90483019e-04 2.58463570e-03 3.00944857e-03\n",
      "  8.86108509e-01 9.35263501e-04]\n",
      " [4.81717709e-04 1.21895237e-03 5.10376888e-02 2.53535937e-06\n",
      "  9.68275630e-03 7.12727095e-01 9.50582829e-04 5.21503644e-04\n",
      "  3.30984800e-04 4.13108432e-02]\n",
      " [5.92224562e-03 9.51116737e-01 7.90351513e-04 9.01343256e-03\n",
      "  8.86470358e-04 4.60366375e-04 1.44895047e-03 8.21110239e-05\n",
      "  1.74931390e-03 2.76230326e-04]\n",
      " [9.53171842e-01 9.86671238e-05 8.23756558e-04 6.05396348e-04\n",
      "  1.67613429e-04 1.74778020e-03 1.46330631e-03 1.29380823e-04\n",
      "  7.52606777e-04 2.36086731e-03]\n",
      " [1.59871384e-03 8.33003955e-04 1.94734149e-04 8.73220926e-01\n",
      "  2.90781208e-03 1.71334039e-03 1.21575102e-03 1.88908448e-04\n",
      "  2.71089694e-04 5.63623191e-05]\n",
      " [1.25727286e-02 8.71687761e-01 1.60682795e-04 3.66869851e-02\n",
      "  3.40991271e-03 1.26008668e-04 1.05525261e-03 1.27725382e-04\n",
      "  6.58000336e-04 2.91403072e-05]\n",
      " [1.18164403e-03 8.10252898e-02 4.29527970e-04 1.39538598e-04\n",
      "  2.69483116e-03 5.91878761e-05 7.94481676e-03 2.34891114e-02\n",
      "  9.28649823e-01 7.84497294e-04]\n",
      " [2.32656335e-03 7.30070350e-04 8.29097536e-01 2.46026020e-05\n",
      "  7.66086249e-03 2.00364882e-02 9.61404460e-05 7.58469097e-04\n",
      "  2.07199511e-03 7.07955025e-04]]\n",
      "REL_D: (24, 16)\n",
      "SOFT_D: (24, 10)\n",
      "LOSS_D: (24, 10)\n",
      "Weights out: [[-0.03796887 -0.06336956  0.01656474  0.02860842  0.02248888  0.05736118\n",
      "  -0.00233096 -0.05698595 -0.03324357  0.02525195]\n",
      " [ 0.01777286  0.00497375  0.02900667  0.02175452  0.06033299  0.01367914\n",
      "   0.04400317 -0.03957107  0.02814078  0.06357   ]\n",
      " [-0.01807172  0.04411536  0.03551769 -0.06964017  0.01288565 -0.05839468\n",
      "   0.07387657  0.04923724 -0.06170978 -0.05983082]\n",
      " [ 0.01493318 -0.0245334  -0.07345646  0.00659426 -0.01772892 -0.06307343\n",
      "   0.0477316   0.06558437  0.04055447  0.05097627]\n",
      " [-0.04482881 -0.03739794 -0.04609633  0.04190711  0.07083054  0.03428509\n",
      "   0.06029923  0.02196424 -0.01774453 -0.01177543]\n",
      " [-0.06702195 -0.07411749  0.03112403 -0.00927853  0.00825794  0.00935306\n",
      "  -0.03521378 -0.00384465 -0.00460609 -0.01752049]\n",
      " [ 0.05038291 -0.00728394  0.01672819  0.0629935   0.05762676  0.06178105\n",
      "  -0.03637712 -0.07348343 -0.03761721 -0.03509732]\n",
      " [ 0.06491155  0.02356722 -0.06609897 -0.05759278 -0.05445168  0.02059661\n",
      "   0.03715865  0.056852    0.06964208 -0.04712242]\n",
      " [-0.03006401 -0.04104863 -0.02231647  0.06556153  0.01180222  0.03793699\n",
      "  -0.00154925 -0.07449673 -0.06885798  0.00598358]\n",
      " [ 0.03456837 -0.04495299  0.03508795  0.04912713 -0.01395967  0.03895311\n",
      "  -0.01518919  0.02817383  0.04176547  0.07776975]\n",
      " [-0.02447045 -0.01406175 -0.05269524 -0.04663929  0.03054675  0.06576964\n",
      "  -0.01663569 -0.05063905 -0.03401158 -0.00713988]\n",
      " [-0.03316307 -0.04232387  0.03880514 -0.07780543  0.00623192  0.04648108\n",
      "  -0.0367133   0.0164038   0.02665382  0.0240919 ]\n",
      " [-0.00858789 -0.02412043  0.05311089  0.04080213 -0.02826825 -0.0627613\n",
      "  -0.06770615 -0.06415148  0.01309838 -0.07088953]\n",
      " [-0.02587975  0.03968063 -0.03177876  0.04190247  0.03835284 -0.04014687\n",
      "   0.03588593  0.04033228 -0.01603407 -0.04562734]\n",
      " [ 0.0034881   0.0653396   0.02325793 -0.0516402   0.02888218 -0.01066155\n",
      "   0.01409456  0.03844473  0.00245446  0.04923107]\n",
      " [ 0.0350683   0.01826467 -0.05514478  0.05336531  0.0687387  -0.05725924\n",
      "  -0.00187677 -0.03806708  0.04032075  0.03496113]]\n",
      "Weights in: [[-0.00224036  0.00804847  0.00414275 ... -0.0051368  -0.0056817\n",
      "  -0.00565349]\n",
      " [-0.00349567  0.00044208 -0.00121527 ... -0.0080991   0.00192044\n",
      "  -0.0058835 ]\n",
      " [-0.00776694  0.00801581  0.00831486 ...  0.00290218 -0.0033623\n",
      "   0.00035836]\n",
      " ...\n",
      " [ 0.00277846  0.00075172  0.00474104 ...  0.00649923 -0.00319014\n",
      "   0.00874223]\n",
      " [-0.0061127   0.00029178  0.00522937 ...  0.00163694 -0.00870254\n",
      "  -0.00890708]\n",
      " [ 0.00207319 -0.00555327 -0.00550201 ... -0.00131872  0.00796151\n",
      "  -0.00504055]]\n",
      "Accurancy : 0.08333333333333333\n",
      "\n",
      "\n",
      "Epoch: 6\n",
      "H: (24, 16)\n",
      "A: (24, 16)\n",
      "H OUTPUT: (24, 10)\n",
      "A OUTPUT: (24, 10)\n",
      "Loss: [[3.41127232e-03 9.07436798e-01 4.58065444e-04 2.48841108e-03\n",
      "  2.52969020e-04 2.48842799e-04 2.95552243e-03 1.36879334e-03\n",
      "  1.56239796e-03 2.96345097e-04]\n",
      " [1.19408806e-03 1.83227635e-04 8.74340686e-01 3.60951306e-04\n",
      "  1.81313474e-03 1.00302305e-02 4.02442644e-04 3.97905616e-04\n",
      "  1.95842313e-03 5.83232664e-04]\n",
      " [5.55585087e-03 8.23857439e-04 1.40596650e-03 6.83689573e-04\n",
      "  1.06229990e-03 2.13772991e-03 9.34469550e-01 1.27308849e-04\n",
      "  2.05426773e-03 1.13829142e-03]\n",
      " [9.86784583e-04 1.06541453e-03 9.48428431e-01 3.96983083e-04\n",
      "  9.28572140e-04 1.24778179e-03 1.08498779e-03 1.09499167e-03\n",
      "  1.24029615e-03 1.45228113e-04]\n",
      " [1.19920462e-04 2.98567319e-02 3.94573415e-03 2.25384001e-06\n",
      "  9.35718710e-03 2.53792450e-04 4.31233823e-03 6.12485363e-02\n",
      "  6.73212531e-03 6.64470924e-01]\n",
      " [1.34227652e-03 2.24657408e-04 5.82869493e-04 5.01604778e-01\n",
      "  1.55270904e-02 1.41203514e-03 7.47703536e-04 2.47945679e-05\n",
      "  2.16014566e-04 6.04598563e-05]\n",
      " [9.50986338e-04 8.24389314e-01 2.71176133e-04 4.82175599e-03\n",
      "  1.66743057e-03 1.43116468e-04 9.11864011e-03 2.18830856e-03\n",
      "  4.58603266e-04 1.18527058e-04]\n",
      " [6.02948225e-04 7.44879218e-04 1.62853601e-03 8.81460286e-05\n",
      "  1.07175255e-04 9.67057146e-01 1.33707787e-03 2.38051912e-03\n",
      "  2.97931113e-03 1.05413486e-03]\n",
      " [1.08123430e-02 7.22904556e-03 1.18492915e-03 3.97118078e-03\n",
      "  1.06637778e-02 6.86343006e-04 3.60758934e-03 1.14600435e-04\n",
      "  9.30575657e-01 2.45177067e-03]\n",
      " [2.56345550e-04 2.77876408e-03 8.95046058e-04 6.81667856e-06\n",
      "  2.95581450e-04 5.28627291e-04 6.11938402e-03 4.10575135e-02\n",
      "  8.51138118e-03 9.34779027e-01]\n",
      " [3.63750225e-03 7.43893670e-04 9.60234238e-04 4.29689203e-04\n",
      "  2.27305282e-04 9.27423553e-01 8.00055938e-04 3.34835229e-04\n",
      "  1.48274170e-03 3.91465333e-04]\n",
      " [3.09245108e-04 2.41317373e-03 3.29831784e-04 3.79954882e-04\n",
      "  7.62806478e-03 9.81866935e-01 4.88133895e-03 2.56721228e-03\n",
      "  4.10438615e-03 8.77160165e-03]\n",
      " [4.13920844e-03 8.91236627e-01 2.57609236e-04 9.75620284e-03\n",
      "  1.19181706e-03 1.46534199e-04 2.16949672e-03 3.61616196e-04\n",
      "  9.75609861e-04 8.72602892e-05]\n",
      " [5.20839401e-03 2.66327366e-03 5.51694662e-03 1.63350504e-04\n",
      "  1.83021198e-03 4.10910688e-03 4.95141276e-04 3.59345214e-04\n",
      "  9.39412231e-01 1.48757789e-03]\n",
      " [3.31151320e-03 2.73672916e-03 9.11230449e-01 1.94125525e-04\n",
      "  6.97225733e-04 1.09460273e-03 1.28160028e-03 5.77247280e-04\n",
      "  1.50164478e-03 2.46846394e-03]\n",
      " [2.90171572e-03 9.79391043e-04 1.41285709e-03 7.74121810e-01\n",
      "  9.05432118e-03 4.64971347e-03 8.11009295e-04 7.84177744e-05\n",
      "  1.59548106e-04 6.95383077e-05]\n",
      " [1.34073182e-03 2.44511684e-03 5.84511355e-03 1.34991354e-04\n",
      "  1.33824356e-03 5.91698755e-04 2.22638103e-03 1.11529909e-03\n",
      "  2.64091206e-03 8.44739575e-01]\n",
      " [5.00141609e-04 3.59617889e-04 9.21740741e-04 1.59118610e-03\n",
      "  4.75190640e-04 8.38743068e-04 9.39327441e-01 3.00159793e-04\n",
      "  4.53240546e-04 2.29191108e-04]\n",
      " [1.13037993e-03 5.26197900e-04 1.89388244e-03 6.52923329e-04\n",
      "  4.80869812e-04 9.28124850e-01 1.74847737e-03 6.01407968e-04\n",
      "  1.07466742e-03 1.82538550e-03]\n",
      " [1.34742362e-04 8.97271728e-05 9.08830182e-01 9.50602678e-05\n",
      "  7.99330833e-05 3.35807624e-04 6.41326672e-04 1.96704249e-03\n",
      "  3.18200490e-03 4.85666798e-04]\n",
      " [9.59545398e-01 8.08022394e-04 2.64205762e-03 8.27396510e-05\n",
      "  2.86930353e-04 1.31818480e-03 2.92955012e-03 8.61499970e-04\n",
      "  1.23337365e-03 9.17892494e-03]\n",
      " [2.11528136e-04 8.88680365e-05 2.28620622e-03 9.12745341e-04\n",
      "  1.79693469e-03 7.53627096e-01 8.29374625e-04 5.59391853e-05\n",
      "  1.85125857e-04 2.29055824e-03]\n",
      " [1.45041759e-03 1.03828937e-04 8.63584587e-01 9.96049620e-05\n",
      "  5.13476977e-04 1.36778829e-02 2.05384807e-04 2.16721375e-04\n",
      "  2.05299789e-03 8.15035232e-04]\n",
      " [5.62857508e-03 9.67395322e-01 2.75699919e-03 6.43324905e-04\n",
      "  1.67592525e-04 2.95094067e-03 4.97540560e-04 6.94198107e-04\n",
      "  4.02918791e-03 1.74687888e-03]]\n",
      "REL_D: (24, 16)\n",
      "SOFT_D: (24, 10)\n",
      "LOSS_D: (24, 10)\n",
      "Weights out: [[-0.03795031 -0.06335321  0.01662381  0.02876309  0.02244452  0.05754976\n",
      "  -0.00235939 -0.05706713 -0.0332441   0.02536221]\n",
      " [ 0.01775987  0.00496575  0.02901501  0.02179438  0.06031886  0.01367409\n",
      "   0.04401775 -0.03957224  0.02816421  0.06362326]\n",
      " [-0.01807172  0.04411536  0.03551769 -0.06964017  0.01288565 -0.05839468\n",
      "   0.07387657  0.04923724 -0.06170978 -0.05983082]\n",
      " [ 0.01493308 -0.02453416 -0.07345656  0.00659413 -0.01773122 -0.06307048\n",
      "   0.0477301   0.06558356  0.0405532   0.05097364]\n",
      " [-0.04482916 -0.03739808 -0.04609377  0.04190694  0.07083039  0.03429323\n",
      "   0.06029879  0.02196408 -0.0177449  -0.01177592]\n",
      " [-0.06703085 -0.07412376  0.03118221 -0.00904145  0.00822802  0.00938424\n",
      "  -0.03520851 -0.00389285 -0.00462053 -0.01740512]\n",
      " [ 0.05030981 -0.00712601  0.01695944  0.06355693  0.0575372   0.06188716\n",
      "  -0.03634063 -0.07349469 -0.03752961 -0.0350651 ]\n",
      " [ 0.06491126  0.02356423 -0.06609996 -0.05759197 -0.05445209  0.02059602\n",
      "   0.03715224  0.0568148   0.06963331 -0.0470872 ]\n",
      " [-0.03006513 -0.04104916 -0.02231919  0.06561127  0.01179499  0.03804371\n",
      "  -0.00152653 -0.07449712 -0.06885871  0.00598085]\n",
      " [ 0.03456215 -0.04492605  0.03509891  0.04912552 -0.01396072  0.03895761\n",
      "  -0.01519151  0.02817236  0.0417606   0.07778085]\n",
      " [-0.0244725  -0.01406259 -0.0526894  -0.04663962  0.0305461   0.06577479\n",
      "  -0.01663003 -0.05063955 -0.03401285 -0.00713241]\n",
      " [-0.03318105 -0.04238777  0.03912445 -0.0777692   0.00618556  0.04661153\n",
      "  -0.03670361  0.01623862  0.02663219  0.02442459]\n",
      " [-0.00858857 -0.02411221  0.05311077  0.04080055 -0.02826848 -0.06276139\n",
      "  -0.0677041  -0.06415156  0.01309819 -0.07088956]\n",
      " [-0.02590735  0.03989784 -0.03169105  0.04225079  0.03827465 -0.0400843\n",
      "   0.03585706  0.04018799 -0.01604899 -0.04536497]\n",
      " [ 0.00348261  0.06527006  0.02327206 -0.05159811  0.02881045 -0.01053272\n",
      "   0.01404951  0.03819507  0.00249068  0.04982981]\n",
      " [ 0.03505746  0.0182648  -0.05514135  0.05345218  0.06870825 -0.05724346\n",
      "  -0.00188248 -0.03810104  0.04033023  0.03502883]]\n",
      "Weights in: [[-0.00224036  0.00804847  0.00414275 ... -0.0051368  -0.0056817\n",
      "  -0.00565349]\n",
      " [-0.00349567  0.00044208 -0.00121527 ... -0.0080991   0.00192044\n",
      "  -0.0058835 ]\n",
      " [-0.00776694  0.00801581  0.00831486 ...  0.00290218 -0.0033623\n",
      "   0.00035836]\n",
      " ...\n",
      " [ 0.00277846  0.00075172  0.00474104 ...  0.00649923 -0.00319014\n",
      "   0.00874223]\n",
      " [-0.0061127   0.00029178  0.00522937 ...  0.00163694 -0.00870254\n",
      "  -0.00890708]\n",
      " [ 0.00207319 -0.00555327 -0.00550201 ... -0.00131872  0.00796151\n",
      "  -0.00504055]]\n",
      "Accurancy : 0.16666666666666666\n",
      "\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H: (24, 16)\n",
      "A: (24, 16)\n",
      "H OUTPUT: (24, 10)\n",
      "A OUTPUT: (24, 10)\n",
      "Loss: [[4.38463099e-03 2.52638218e-02 6.90403044e-04 2.68381070e-06\n",
      "  1.09333915e-04 3.46442939e-05 7.59081577e-03 6.67603012e-01\n",
      "  1.18264099e-02 3.11216444e-03]\n",
      " [2.97866719e-03 1.18158747e-03 4.53413009e-03 4.06893103e-05\n",
      "  3.60820371e-03 1.49961068e-03 9.64083562e-01 9.31695402e-04\n",
      "  1.74076682e-03 3.71048704e-04]\n",
      " [9.41734849e-01 5.31364369e-05 7.65431425e-04 8.03818448e-03\n",
      "  8.91432416e-04 1.94146229e-03 1.93849813e-03 3.49737740e-05\n",
      "  1.94663935e-04 6.53182381e-04]\n",
      " [1.35180055e-04 8.23684507e-04 2.33505486e-02 1.70485332e-07\n",
      "  9.03486960e-04 1.54298083e-03 9.63161029e-04 8.87132633e-03\n",
      "  6.19023756e-03 4.94210006e-01]\n",
      " [3.35942473e-03 1.06327667e-03 3.64918827e-03 2.83030467e-05\n",
      "  2.82776433e-03 8.59683630e-04 9.61158153e-01 6.61312126e-04\n",
      "  3.19867703e-03 1.81438341e-03]\n",
      " [1.32565503e-03 5.09803182e-05 2.51936046e-04 2.05573194e-01\n",
      "  6.13545579e-03 6.45966961e-03 7.44258962e-04 1.07114909e-06\n",
      "  6.68225620e-06 5.38348710e-05]\n",
      " [5.61941201e-04 1.67575620e-04 1.32245036e-03 3.46559522e-05\n",
      "  5.25163791e-04 3.84364872e-04 7.21942612e-04 1.58356108e-03\n",
      "  8.51583820e-01 9.11641918e-04]\n",
      " [1.12425321e-03 2.16023700e-03 8.56658513e-01 4.40877234e-05\n",
      "  1.49831924e-02 3.39438528e-03 5.27048144e-04 5.99062454e-04\n",
      "  4.32874042e-04 1.41763903e-03]\n",
      " [2.55063505e-05 5.42966195e-04 7.69343104e-04 4.22860010e-05\n",
      "  2.20069453e-03 3.15986302e-04 3.78533611e-03 5.35353839e-03\n",
      "  9.51738178e-01 1.05886794e-03]\n",
      " [5.78757699e-04 2.06907915e-04 9.33280057e-01 1.32526152e-04\n",
      "  1.11804929e-03 1.05113454e-03 5.43236873e-04 6.16268155e-04\n",
      "  1.02907697e-03 1.91260289e-04]\n",
      " [7.26285233e-04 1.51145549e-04 1.24015404e-03 3.55267171e-05\n",
      "  5.44539438e-05 9.75665509e-01 1.08933126e-03 1.19914370e-03\n",
      "  4.19489018e-03 9.63901993e-04]\n",
      " [1.38696802e-02 5.28699822e-03 1.16214949e-03 3.91913045e-04\n",
      "  1.08773367e-03 1.72355892e-04 2.38677144e-03 9.58584084e-01\n",
      "  1.40793868e-03 6.43910670e-04]\n",
      " [2.26627860e-03 7.04687757e-03 1.08749401e-03 2.76782675e-05\n",
      "  2.09382632e-04 2.49833144e-05 7.15240781e-03 8.58338726e-01\n",
      "  4.41913824e-03 2.69242916e-03]\n",
      " [1.20004435e-04 3.62210074e-06 1.45483421e-03 1.05640489e-02\n",
      "  4.34581634e-03 7.12099229e-01 2.44035814e-04 2.01259179e-06\n",
      "  2.46761236e-05 3.11613463e-04]\n",
      " [2.10345173e-04 2.37993925e-04 2.90977544e-03 2.47580763e-06\n",
      "  1.88874855e-04 3.69216091e-04 9.12762103e-04 2.91296989e-03\n",
      "  4.20196380e-03 8.80874192e-01]\n",
      " [1.53928108e-03 1.94815189e-04 2.48687953e-04 1.82102143e-05\n",
      "  2.00506591e-04 3.32854446e-03 9.32007258e-01 1.41896338e-03\n",
      "  3.77675796e-03 1.79427423e-04]\n",
      " [1.72077829e-03 4.73659567e-03 3.86739857e-03 1.37491109e-05\n",
      "  4.98225368e-04 9.91195076e-05 1.70696135e-03 2.96540539e-03\n",
      "  2.13012473e-03 8.67113487e-01]\n",
      " [1.22966123e-03 1.13487021e-02 3.78180705e-04 2.70008693e-05\n",
      "  2.74046279e-04 2.34450268e-05 6.71889281e-03 8.00038126e-01\n",
      "  2.91215037e-03 9.40166532e-04]\n",
      " [2.25418917e-03 8.32089969e-04 9.72180738e-01 1.94726794e-04\n",
      "  1.92183559e-04 1.88139066e-04 1.84425076e-03 4.00958660e-04\n",
      "  1.01579876e-03 2.55397625e-04]\n",
      " [4.13932936e-04 2.06650300e-04 9.42405435e-01 1.29562298e-03\n",
      "  5.95321354e-03 1.97395631e-03 9.99638827e-04 1.61751750e-04\n",
      "  2.34968186e-04 1.41488093e-04]\n",
      " [2.06744175e-03 1.14573382e-02 4.79960835e-04 2.80176875e-04\n",
      "  1.52000087e-03 7.66243523e-05 6.81064353e-03 2.64545640e-03\n",
      "  7.52787520e-04 9.56237808e-01]\n",
      " [2.04345029e-03 7.52003501e-05 7.45039919e-03 9.71271207e-01\n",
      "  8.52955121e-03 6.08945022e-02 2.29966289e-04 6.88959520e-06\n",
      "  1.48393489e-04 3.20577567e-03]\n",
      " [5.76609464e-03 8.58895502e-01 1.56592754e-04 3.07831421e-03\n",
      "  3.50259619e-03 3.29142870e-05 3.97213586e-03 5.05240959e-04\n",
      "  1.28776247e-03 2.40888841e-04]\n",
      " [7.97440811e-03 6.79880548e-04 9.57638649e-01 1.17444332e-03\n",
      "  1.87544468e-03 1.34470418e-03 1.07017723e-03 3.59529870e-05\n",
      "  4.16996246e-04 2.50329946e-04]]\n",
      "REL_D: (24, 16)\n",
      "SOFT_D: (24, 10)\n",
      "LOSS_D: (24, 10)\n",
      "Weights out: [[-0.03790034 -0.06333248  0.01660847  0.02886687  0.02239728  0.05753403\n",
      "  -0.00237209 -0.05709171 -0.03320151  0.02566757]\n",
      " [ 0.01775023  0.00496068  0.02902895  0.02179092  0.06031541  0.01370235\n",
      "   0.04401333 -0.03953779  0.02816168  0.06362192]\n",
      " [-0.01807189  0.04411485  0.0355176  -0.06964017  0.01288563 -0.05839468\n",
      "   0.07387605  0.0492423  -0.06171012 -0.05983102]\n",
      " [ 0.01493308 -0.02453421 -0.07345656  0.00659413 -0.01773123 -0.06307048\n",
      "   0.04773007  0.06558393  0.04055319  0.05097363]\n",
      " [-0.04482916 -0.03739808 -0.04609377  0.04190694  0.07083039  0.03429323\n",
      "   0.06029879  0.02196408 -0.0177449  -0.01177592]\n",
      " [-0.06703594 -0.07413393  0.03117065 -0.0090044   0.00821896  0.00949263\n",
      "  -0.03521016 -0.00386305 -0.0046326  -0.01727905]\n",
      " [ 0.05027085 -0.00707769  0.01719781  0.06384461  0.05743057  0.06194496\n",
      "  -0.03626429 -0.07347626 -0.03751545 -0.03502269]\n",
      " [ 0.06490637  0.02354863 -0.06610154 -0.05759203 -0.05445268  0.02059188\n",
      "   0.03718782  0.05689118  0.06962075 -0.04707148]\n",
      " [-0.0300643  -0.04105628 -0.0221979   0.06586123  0.01174673  0.03830367\n",
      "  -0.00148988 -0.07450829 -0.06883405  0.00598273]\n",
      " [ 0.03457155 -0.0449261   0.03509846  0.04912302 -0.01396113  0.03895692\n",
      "  -0.01519179  0.02817218  0.04176708  0.07778051]\n",
      " [-0.02447968 -0.01406655 -0.05267289 -0.04663329  0.03054081  0.06575043\n",
      "  -0.01663399 -0.05061645 -0.03401601 -0.00711494]\n",
      " [-0.03321024 -0.04241587  0.0393399  -0.07777476  0.0061008   0.04671298\n",
      "  -0.0365689   0.01625171  0.02679422  0.02486514]\n",
      " [-0.00858857 -0.02411221  0.05311077  0.04080055 -0.02826848 -0.06276139\n",
      "  -0.0677041  -0.06415156  0.01309819 -0.07088956]\n",
      " [-0.0259211   0.03995201 -0.03146116  0.04238304  0.03819837 -0.0399978\n",
      "   0.03588263  0.0403484  -0.01592839 -0.04528181]\n",
      " [ 0.00342712  0.06518961  0.02332976 -0.05157806  0.02874321 -0.01062834\n",
      "   0.01404197  0.03867046  0.00244203  0.05054107]\n",
      " [ 0.03505154  0.0183155  -0.05514344  0.05344979  0.06870421 -0.05724398\n",
      "  -0.00187761 -0.0381023   0.04035282  0.03502754]]\n",
      "Weights in: [[-0.00224036  0.00804847  0.00414275 ... -0.0051368  -0.0056817\n",
      "  -0.00565349]\n",
      " [-0.00349567  0.00044208 -0.00121527 ... -0.0080991   0.00192044\n",
      "  -0.0058835 ]\n",
      " [-0.00776694  0.00801581  0.00831486 ...  0.00290218 -0.0033623\n",
      "   0.00035836]\n",
      " ...\n",
      " [ 0.00277846  0.00075172  0.00474104 ...  0.00649923 -0.00319014\n",
      "   0.00874223]\n",
      " [-0.0061127   0.00029178  0.00522937 ...  0.00163694 -0.00870254\n",
      "  -0.00890708]\n",
      " [ 0.00207319 -0.00555327 -0.00550201 ... -0.00131872  0.00796151\n",
      "  -0.00504055]]\n",
      "Accurancy : 0.25\n",
      "\n",
      "\n",
      "Epoch: 8\n",
      "H: (24, 16)\n",
      "A: (24, 16)\n",
      "H OUTPUT: (24, 10)\n",
      "A OUTPUT: (24, 10)\n",
      "Loss: [[2.82541420e-03 7.61885728e-03 7.47873159e-04 4.47913038e-05\n",
      "  9.20495197e-05 8.40554132e-06 4.49092916e-03 5.06125343e-03\n",
      "  4.14003270e-03 9.10666559e-01]\n",
      " [4.42631879e-04 2.85350190e-05 2.17071050e-04 2.55728826e-02\n",
      "  7.29976644e-04 3.72678467e-04 1.03377144e-03 7.03841180e-06\n",
      "  7.75759169e-05 9.80043218e-01]\n",
      " [1.13112281e-03 9.21045600e-04 5.00289940e-03 6.67036729e-06\n",
      "  9.68698991e-01 5.99051398e-05 8.56071558e-04 3.54332602e-03\n",
      "  1.08490742e-02 3.50392789e-03]\n",
      " [4.70195742e-04 1.17326583e-05 4.57648349e-04 2.25258470e-03\n",
      "  4.67950937e-04 5.62064881e-04 2.77824683e-04 2.65624433e-05\n",
      "  9.47773999e-01 1.86452500e-04]\n",
      " [9.39318862e-01 3.00742744e-04 5.26669538e-04 4.91137739e-04\n",
      "  2.36233352e-04 3.82391821e-04 2.95380934e-03 8.90655391e-05\n",
      "  3.17412569e-04 3.04644635e-03]\n",
      " [3.30121454e-04 6.99863010e-05 1.98096557e-03 1.07664370e-04\n",
      "  9.80062522e-01 6.38629421e-05 6.45110326e-04 6.65601973e-04\n",
      "  2.59247354e-03 5.77062712e-04]\n",
      " [9.22458665e-01 1.68439596e-03 4.90670928e-03 7.81776538e-06\n",
      "  3.66571169e-04 1.44496153e-04 9.16438443e-04 2.18431101e-03\n",
      "  4.20830391e-03 6.19854407e-03]\n",
      " [5.30121196e-04 7.57707960e-04 3.59397774e-04 1.27267218e-03\n",
      "  7.16765951e-04 3.61130779e-05 3.70117549e-03 9.27967622e-01\n",
      "  1.03425259e-03 1.05014597e-04]\n",
      " [8.91843534e-01 1.29564839e-03 1.59690011e-03 4.21007639e-04\n",
      "  2.55141621e-04 7.83957097e-05 3.30484543e-03 5.70826275e-04\n",
      "  1.37163477e-03 6.18010378e-03]\n",
      " [9.77762033e-01 9.76931795e-06 3.29145545e-04 2.27467815e-03\n",
      "  2.15264191e-04 6.98883242e-04 5.77406012e-04 4.14982514e-05\n",
      "  2.45306323e-04 1.64728751e-04]\n",
      " [3.55035242e-02 2.59813764e-05 4.94081280e-03 6.41601437e-01\n",
      "  9.08817044e-02 4.04319139e-01 1.71013982e-05 9.54150230e-08\n",
      "  2.01106563e-05 4.05809672e-05]\n",
      " [8.11520020e-03 6.19918948e-04 5.07057677e-03 4.65908388e-05\n",
      "  7.01472862e-04 6.10164713e-04 1.84241323e-04 3.44937712e-04\n",
      "  8.92974756e-01 6.20324449e-04]\n",
      " [2.15365292e-04 3.22392587e-03 3.89826793e-03 1.71957162e-06\n",
      "  4.87951516e-03 5.54977751e-05 1.68644078e-03 9.33186660e-03\n",
      "  1.30991097e-02 5.48357249e-01]\n",
      " [1.10476905e-04 1.69155222e-03 2.91044628e-03 5.91921101e-06\n",
      "  8.52781693e-04 5.45249450e-05 2.71184122e-03 7.52393414e-01\n",
      "  4.33678581e-03 3.55483353e-03]\n",
      " [9.54172093e-01 6.17106797e-05 6.04846840e-04 2.50932832e-03\n",
      "  2.21503366e-04 4.25906219e-04 1.66883595e-03 2.33361015e-05\n",
      "  1.70517122e-04 1.59874347e-03]\n",
      " [9.16833602e-01 2.77988091e-04 7.97764571e-05 2.91247901e-02\n",
      "  5.84620103e-04 2.09716894e-05 5.47664849e-03 2.36198458e-04\n",
      "  3.59333694e-04 9.74132769e-05]\n",
      " [9.23117863e-03 3.78879275e-04 7.20410951e-03 2.86774968e-03\n",
      "  1.84452185e-02 3.73601923e-03 4.70073560e-04 9.73695614e-06\n",
      "  9.65487040e-01 1.03277494e-03]\n",
      " [2.49849849e-03 1.37418767e-04 7.95815295e-04 8.22565291e-01\n",
      "  1.17896056e-03 5.03221233e-04 1.09168522e-03 2.33886874e-05\n",
      "  1.49681850e-04 9.74888942e-05]\n",
      " [7.31752958e-04 7.33332323e-05 1.73024508e-03 5.64687248e-05\n",
      "  3.06826812e-04 3.65287907e-04 9.58861423e-01 5.08795955e-04\n",
      "  5.26759635e-03 4.15020173e-04]\n",
      " [2.99033132e-04 6.19789968e-02 3.02345347e-04 1.29318586e-04\n",
      "  3.70032022e-03 2.28983641e-06 2.23491046e-02 5.85470470e-01\n",
      "  2.19138160e-03 7.05166488e-04]\n",
      " [9.78915200e-01 2.55996857e-05 1.61999720e-03 2.50058219e-04\n",
      "  4.64011828e-04 9.78057698e-04 8.54851950e-04 1.15370947e-04\n",
      "  5.15105797e-04 1.61488161e-03]\n",
      " [2.27579510e-03 6.63420897e-02 6.92670400e-04 1.00293509e-04\n",
      "  2.56571929e-03 1.00493811e-05 5.83627202e-03 7.74387573e-01\n",
      "  1.65075025e-03 4.58730389e-04]\n",
      " [9.25109418e-01 1.00137027e-04 1.28295430e-03 3.14368790e-04\n",
      "  1.36371353e-04 2.10487191e-04 7.98181649e-04 1.76098611e-04\n",
      "  1.71142569e-03 6.24577365e-04]\n",
      " [1.28692389e-03 6.98384900e-04 8.36562246e-01 2.26820691e-05\n",
      "  6.54924478e-04 1.37700134e-04 3.21712211e-04 1.21668169e-03\n",
      "  2.72557475e-03 1.29551328e-03]]\n",
      "REL_D: (24, 16)\n",
      "SOFT_D: (24, 10)\n",
      "LOSS_D: (24, 10)\n",
      "Weights out: [[-0.03753681 -0.06345358  0.0165937   0.02917685  0.02224052  0.05724115\n",
      "  -0.00244499 -0.05663094 -0.03318886  0.02598206]\n",
      " [ 0.0177428   0.00495996  0.02902098  0.02178067  0.06030935  0.01369927\n",
      "   0.04402103 -0.03953948  0.02817059  0.06362314]\n",
      " [-0.01807239  0.04411482  0.03551744 -0.06962401  0.01288539 -0.05839479\n",
      "   0.07387583  0.0492423  -0.06171015 -0.05983104]\n",
      " [ 0.01496072 -0.0245344  -0.07345662  0.00657699 -0.01773163 -0.06307049\n",
      "   0.04772647  0.06558377  0.04055294  0.05097356]\n",
      " [-0.04482916 -0.03739808 -0.04609377  0.04190694  0.07083039  0.03429323\n",
      "   0.06029879  0.02196408 -0.0177449  -0.01177592]\n",
      " [-0.06701826 -0.0741359   0.03125102 -0.00904059  0.0082356   0.00949097\n",
      "  -0.03521611 -0.00385398 -0.00463516 -0.01727393]\n",
      " [ 0.05022612 -0.00714551  0.01722775  0.06460813  0.05703818  0.06113429\n",
      "  -0.03627643 -0.07333761 -0.03735628 -0.03503057]\n",
      " [ 0.06491844  0.02354851 -0.06610175 -0.05759224 -0.05445277  0.02059172\n",
      "   0.03718665  0.05689114  0.06962062 -0.04707268]\n",
      " [-0.02996652 -0.0410573  -0.02220964  0.06593615  0.01168992  0.03818923\n",
      "  -0.00149554 -0.07450902 -0.06879474  0.00598946]\n",
      " [ 0.034593   -0.04492664  0.03509779  0.04912284 -0.01396124  0.03895689\n",
      "  -0.01519314  0.02817194  0.04176651  0.07777805]\n",
      " [-0.0244958  -0.01407199 -0.05267573 -0.04657339  0.03050581  0.06567047\n",
      "  -0.01663271 -0.05060632 -0.0340168  -0.00711082]\n",
      " [-0.03307207 -0.0425992   0.03936997 -0.07741161  0.00592372  0.04633116\n",
      "  -0.03658304  0.01691934  0.02690067  0.02534442]\n",
      " [-0.00858857 -0.02411221  0.05311077  0.04080055 -0.02826848 -0.06276139\n",
      "  -0.0677041  -0.06415156  0.01309819 -0.07088956]\n",
      " [-0.02586996  0.03969102 -0.03148281  0.04244332  0.03813497 -0.04006735\n",
      "   0.03580198  0.04121751 -0.01593918 -0.04512548]\n",
      " [ 0.00377661  0.06480393  0.02344177 -0.05138158  0.02861518 -0.01084857\n",
      "   0.01390225  0.03974353  0.0024381   0.05118162]\n",
      " [ 0.03505104  0.01829886 -0.05514736  0.05344881  0.06869848 -0.05724428\n",
      "  -0.0018849  -0.03807047  0.0403516   0.03516872]]\n",
      "Weights in: [[-0.00224036  0.00804847  0.00414275 ... -0.0051368  -0.0056817\n",
      "  -0.00565349]\n",
      " [-0.00349567  0.00044208 -0.00121527 ... -0.0080991   0.00192044\n",
      "  -0.0058835 ]\n",
      " [-0.00776694  0.00801581  0.00831486 ...  0.00290218 -0.0033623\n",
      "   0.00035836]\n",
      " ...\n",
      " [ 0.00277846  0.00075172  0.00474104 ...  0.00649923 -0.00319014\n",
      "   0.00874223]\n",
      " [-0.0061127   0.00029178  0.00522937 ...  0.00163694 -0.00870254\n",
      "  -0.00890708]\n",
      " [ 0.00207319 -0.00555327 -0.00550201 ... -0.00131872  0.00796151\n",
      "  -0.00504055]]\n",
      "Accurancy : 0.16666666666666666\n",
      "\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H: (24, 16)\n",
      "A: (24, 16)\n",
      "H OUTPUT: (24, 10)\n",
      "A OUTPUT: (24, 10)\n",
      "Loss: [[9.38260686e-04 9.14956059e-04 5.93757577e-04 1.75649318e-05\n",
      "  1.85253228e-04 1.20362187e-04 1.94404994e-03 2.04382070e-03\n",
      "  8.89687506e-01 6.44875616e-04]\n",
      " [2.41923873e-03 6.45248191e-05 3.05030548e-03 9.89746256e-01\n",
      "  3.58360400e-04 4.17518906e-03 3.82860868e-04 8.17845638e-05\n",
      "  8.76578720e-04 1.78120579e-04]\n",
      " [5.28145729e-03 6.16410049e-04 1.38603278e-04 5.69566563e-01\n",
      "  4.94676837e-02 6.57356136e-04 6.39829260e-04 5.51594410e-06\n",
      "  6.23746088e-05 5.08723315e-05]\n",
      " [2.63233929e-03 2.76386165e-04 4.01106324e-04 2.61312313e-05\n",
      "  2.65044270e-05 9.70094904e-01 1.33696099e-03 7.57290851e-04\n",
      "  4.00028580e-03 2.50320119e-04]\n",
      " [2.36901049e-04 2.16358799e-02 1.07753857e-03 1.46444239e-06\n",
      "  1.65760718e-03 8.48273475e-05 6.35712676e-03 5.20401877e-02\n",
      "  1.95612680e-03 8.84625175e-01]\n",
      " [9.65268630e-01 2.12992513e-04 1.34932734e-03 3.25484768e-05\n",
      "  4.24020660e-04 7.01491402e-04 1.44705189e-03 7.31822454e-04\n",
      "  1.03532472e-03 5.80385498e-04]\n",
      " [2.11473260e-04 1.89140174e-05 1.04834676e-03 9.85205784e-01\n",
      "  2.06663418e-04 2.35654482e-03 5.19578660e-04 5.57118819e-05\n",
      "  5.38117195e-04 7.46217677e-04]\n",
      " [9.35118306e-01 1.97328374e-05 5.82665511e-04 1.43785264e-03\n",
      "  3.26682930e-04 1.02038702e-02 4.80663777e-04 4.34783313e-06\n",
      "  7.93146133e-05 3.38962932e-04]\n",
      " [1.49833053e-03 2.82658073e-02 3.09958234e-04 1.93650170e-05\n",
      "  4.71516861e-04 5.13114371e-05 1.48540892e-02 8.12835243e-01\n",
      "  1.23603617e-03 1.03141744e-03]\n",
      " [3.05795569e-03 1.15015407e-02 1.52471204e-03 4.78341667e-06\n",
      "  3.33541622e-04 9.36684589e-05 5.91959448e-03 8.75428046e-01\n",
      "  4.34175970e-03 5.21643542e-03]\n",
      " [9.00273042e-03 8.59971322e-01 4.44978044e-04 4.96454305e-04\n",
      "  8.60924087e-04 2.01368577e-04 2.46417605e-03 6.52522722e-04\n",
      "  6.60501234e-04 1.22393793e-04]\n",
      " [9.30724474e-01 4.58318653e-03 1.33380169e-03 1.40252310e-05\n",
      "  3.75502318e-04 2.16437034e-04 5.31429073e-03 1.53072897e-03\n",
      "  9.55265923e-04 5.13990650e-03]\n",
      " [1.04377158e-02 5.97316879e-03 1.36724953e-03 9.66368821e-01\n",
      "  9.41812954e-03 1.32209898e-03 1.09021479e-03 8.68893563e-05\n",
      "  2.52712123e-04 1.06945527e-03]\n",
      " [5.32204207e-04 1.16937750e-03 1.23845711e-02 3.80899059e-08\n",
      "  2.02181078e-04 1.15128046e-03 9.59003689e-01 1.37363864e-02\n",
      "  1.43619987e-02 1.71467014e-02]\n",
      " [1.24902040e-03 3.57689679e-05 2.91093614e-03 9.52431996e-01\n",
      "  1.43030744e-03 8.31087849e-03 3.46778872e-04 1.06542095e-05\n",
      "  1.71515861e-04 4.83926982e-04]\n",
      " [1.93464028e-04 6.47018233e-04 9.17942200e-03 2.77189760e-06\n",
      "  1.22782357e-02 1.09946049e-02 4.23502682e-04 1.36995541e-03\n",
      "  9.49350240e-01 2.25942852e-03]\n",
      " [1.26223438e-03 3.66977982e-04 6.76576800e-04 2.97429076e-05\n",
      "  1.52209014e-04 3.16686706e-04 9.28957920e-01 1.10176134e-03\n",
      "  3.13123067e-03 2.14592262e-04]\n",
      " [1.54534841e-03 8.39899081e-03 1.13179982e-03 5.84705699e-06\n",
      "  1.58231287e-04 3.10702798e-05 7.75980514e-03 8.45907473e-01\n",
      "  1.13400340e-03 5.55367346e-04]\n",
      " [1.25096428e-03 4.49104533e-04 4.74820420e-03 7.04644577e-07\n",
      "  1.61604720e-04 1.33065443e-03 9.61513506e-01 2.16527678e-03\n",
      "  6.50163638e-03 2.60299109e-03]\n",
      " [1.34363668e-03 1.58445200e-05 9.15522956e-01 1.73201495e-04\n",
      "  2.36025404e-03 3.60335844e-02 6.22020708e-05 1.41090182e-05\n",
      "  3.95542804e-04 1.23836401e-04]\n",
      " [1.61318949e-04 6.93649902e-05 2.73910555e-03 3.88773747e-06\n",
      "  3.10614968e-04 9.18338863e-01 1.06958429e-03 1.15118071e-03\n",
      "  2.22388072e-03 2.61914862e-03]\n",
      " [2.93372216e-03 2.15174109e-04 1.04772358e-02 2.70857108e-05\n",
      "  9.68628799e-01 6.97170046e-04 1.74870632e-03 2.53316497e-03\n",
      "  2.03225592e-02 5.08486707e-02]\n",
      " [1.50438216e-03 1.26900669e-04 4.03405413e-05 2.20864231e-01\n",
      "  2.26869161e-02 2.11623101e-03 1.49787132e-03 1.16813605e-06\n",
      "  1.67327668e-05 4.96026630e-05]\n",
      " [4.17525851e-03 9.58578371e-01 3.04716173e-04 2.85168543e-03\n",
      "  7.44427548e-04 5.11681998e-04 1.08213986e-03 6.10457271e-05\n",
      "  3.19232753e-04 2.18546345e-05]]\n",
      "REL_D: (24, 16)\n",
      "SOFT_D: (24, 10)\n",
      "LOSS_D: (24, 10)\n",
      "Weights out: [[-0.03745209 -0.06347667  0.01657132  0.02932461  0.02220085  0.05724378\n",
      "  -0.00246512 -0.05659668 -0.03315854  0.02596673]\n",
      " [ 0.01773614  0.00495741  0.02900882  0.02181203  0.0603205   0.01369633\n",
      "   0.04402181 -0.03951043  0.02814861  0.06357786]\n",
      " [-0.01807421  0.04411066  0.03551558 -0.06962179  0.01288515 -0.05839651\n",
      "   0.07387184  0.04927903 -0.06171111 -0.05983141]\n",
      " [ 0.01496041 -0.02453772 -0.07345682  0.0065848  -0.01773406 -0.06307054\n",
      "   0.04772539  0.06557662  0.0405526   0.05098292]\n",
      " [-0.04482923 -0.03739811 -0.04609495  0.04190694  0.07083025  0.03431057\n",
      "   0.06029832  0.02196358 -0.01774586 -0.01177704]\n",
      " [-0.06702121 -0.0741404   0.03123547 -0.00886797  0.00820835  0.00950454\n",
      "  -0.03522327 -0.0038311  -0.00464212 -0.01731473]\n",
      " [ 0.05020365 -0.00703874  0.01728882  0.06531298  0.05684555  0.06101158\n",
      "  -0.0362705  -0.07334267 -0.03732768 -0.03503999]\n",
      " [ 0.0649176   0.02354097 -0.06610192 -0.05759225 -0.05445293  0.02059371\n",
      "   0.03718232  0.05691689  0.06961967 -0.0470731 ]\n",
      " [-0.02993613 -0.0410703  -0.02216977  0.06644098  0.01157314  0.03811932\n",
      "  -0.00151091 -0.07451106 -0.06878241  0.00602073]\n",
      " [ 0.03458729 -0.04491425  0.03508396  0.0491227  -0.01393903  0.03895586\n",
      "  -0.01519606  0.02816829  0.04174092  0.07772049]\n",
      " [-0.02449587 -0.01407199 -0.05267607 -0.04657098  0.03050574  0.06566973\n",
      "  -0.01663288 -0.05060634 -0.03401697 -0.00711106]\n",
      " [-0.03305906 -0.04264648  0.03940029 -0.0773026   0.00586077  0.04623987\n",
      "  -0.03645826  0.01681356  0.02695075  0.0253617 ]\n",
      " [-0.00858929 -0.02410854  0.05311072  0.04080005 -0.02826861 -0.06276148\n",
      "  -0.0677043  -0.06415157  0.01309813 -0.07088957]\n",
      " [-0.02587982  0.03971087 -0.03147251  0.04297578  0.03798078 -0.04012369\n",
      "   0.03577949  0.04129072 -0.01586209 -0.04501929]\n",
      " [ 0.00382643  0.06467798  0.0233309  -0.05107693  0.028514   -0.01084347\n",
      "   0.01387705  0.04007082  0.00245715  0.05119942]\n",
      " [ 0.03503945  0.01829552 -0.05513717  0.05372655  0.06863222 -0.05725681\n",
      "  -0.00188796 -0.03807103  0.04036431  0.03516788]]\n",
      "Weights in: [[-0.00224036  0.00804847  0.00414275 ... -0.0051368  -0.0056817\n",
      "  -0.00565349]\n",
      " [-0.00349567  0.00044208 -0.00121527 ... -0.0080991   0.00192044\n",
      "  -0.0058835 ]\n",
      " [-0.00776694  0.00801581  0.00831486 ...  0.00290218 -0.0033623\n",
      "   0.00035836]\n",
      " ...\n",
      " [ 0.00277846  0.00075172  0.00474104 ...  0.00649923 -0.00319014\n",
      "   0.00874223]\n",
      " [-0.0061127   0.00029178  0.00522937 ...  0.00163694 -0.00870254\n",
      "  -0.00890708]\n",
      " [ 0.00207319 -0.00555327 -0.00550201 ... -0.00131872  0.00796151\n",
      "  -0.00504055]]\n",
      "Accurancy : 0.125\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 10,\n",
    "                      logs=True, alpha = 0.0001, opt = \"sdg\", isL2 = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.17095238095238094\n"
     ]
    }
   ],
   "source": [
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 100,\n",
    "                      logs=False, alpha = 0.0001, opt = \"sdg\", isL2 = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.3578253968253968\n"
     ]
    }
   ],
   "source": [
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 200,\n",
    "                      logs=False, alpha = 0.0001, opt = \"sdg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.26165079365079363\n"
     ]
    }
   ],
   "source": [
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 500,\n",
    "                      logs=False, alpha = 0.0001, opt = \"sdg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.305952380952381\n"
     ]
    }
   ],
   "source": [
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 300,\n",
    "                      logs=False, alpha = 0.0001, opt = \"sdg\", isL2 = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.24722222222222223\n"
     ]
    }
   ],
   "source": [
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.3902380952380952\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 500,\n",
    "                      logs=False, alpha = 0.0001, opt = \"adam\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.18752380952380954\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 100,\n",
    "                      logs=False, alpha = 0.001, opt = \"adam\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.378047619047619\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 100,\n",
    "                      logs=False, alpha = 0.001, opt = \"adam\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.2614761904761905\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 50,\n",
    "                      logs=False, alpha = 0.0001, opt = \"momentum\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.4408888888888889\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 500,\n",
    "                      logs=False, alpha = 0.0001, opt = \"rmspro\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.149\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 30,\n",
    "                      logs=False, alpha = 0.0001, opt = \"momentum\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.3964920634920635\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 500,\n",
    "                      logs=False, alpha = 0.0001, opt = \"adaGrad\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.24171428571428571\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 100,\n",
    "                      logs=False, alpha = 0.0001, opt = \"adaGrad\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.13766666666666666\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 30,\n",
    "                      logs=False, alpha = 0.01, opt = \"adaGrad\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.21384126984126983\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 30,\n",
    "                      logs=False, alpha = 0.0001, opt = \"momentum\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.36823809523809525\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 200,\n",
    "                      logs=False, alpha = 0.0001, opt = \"adaGrad\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.4603968253968254\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 50,\n",
    "                      logs=False, alpha = 0.001, opt = \"adaGrad\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.4935079365079365\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 150,\n",
    "                      logs=False, alpha = 0.0001, opt = \"rmspro\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.21787301587301589\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 50,\n",
    "                      logs=False, alpha = 0.001, opt = \"rmspro\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5929523809523809\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 200,\n",
    "                      logs=False, alpha = 0.0001, opt = \"rmspro\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.3832857142857143\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 200,\n",
    "                      logs=False, alpha = 0.0001, opt = \"adam\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.23766666666666666\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 50,\n",
    "                      logs=False, alpha = 0.001, opt = \"rmspro\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5407301587301587\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 200,\n",
    "                      logs=False, alpha = 0.0001, opt = \"adaGrad\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = False\n",
    "batchSize = 256\n",
    "outputLayerNeurons = 10\n",
    "hiddenLayerNeurons = 32\n",
    "\n",
    "train_X, test_X , train_y, test_y = train_test_split(x, y, test_size=0.10, random_state=11)\n",
    "\n",
    "w1, w2 = network_init(train_X,\n",
    "                               outputLayerNeurons = outputLayerNeurons,\n",
    "                               hiddenLayerNeurons = hiddenLayerNeurons)\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "l1=init(28*28,hiddenLayerNeurons)\n",
    "l2=init(hiddenLayerNeurons,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.3757142857142857\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 200,\n",
    "                      logs=False, alpha = 0.0001, opt = \"sgd\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.264031746031746\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 300,\n",
    "                      logs=False, alpha = 0.0001, opt = \"sgd\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.30842857142857144\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 200,\n",
    "                      logs=False, alpha = 0.0001, opt = \"sgd\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = False\n",
    "batchSize = 128\n",
    "outputLayerNeurons = 10\n",
    "hiddenLayerNeurons = 32\n",
    "\n",
    "train_X, test_X , train_y, test_y = train_test_split(x, y, test_size=0.10, random_state=11)\n",
    "\n",
    "w1, w2 = network_init(train_X,\n",
    "                               outputLayerNeurons = outputLayerNeurons,\n",
    "                               hiddenLayerNeurons = hiddenLayerNeurons)\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "l1=init(28*28,hiddenLayerNeurons)\n",
    "l2=init(hiddenLayerNeurons,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.35603174603174603\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 100,\n",
    "                      logs=False, alpha = 0.0001, opt = \"sgd\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.34525396825396826\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 200,\n",
    "                      logs=False, alpha = 0.0001, opt = \"sgd\", isL2 = True)\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = False\n",
    "batchSize = 64\n",
    "outputLayerNeurons = 10\n",
    "hiddenLayerNeurons = 32\n",
    "\n",
    "train_X, test_X , train_y, test_y = train_test_split(x, y, test_size=0.10, random_state=11)\n",
    "\n",
    "w1, w2 = network_init(train_X,\n",
    "                               outputLayerNeurons = outputLayerNeurons,\n",
    "                               hiddenLayerNeurons = hiddenLayerNeurons)\n",
    "\n",
    "np.random.seed(42)\n",
    "l1=init(28*28,hiddenLayerNeurons)\n",
    "l2=init(hiddenLayerNeurons,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.20803174603174604\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 200,\n",
    "                      logs=False, alpha = 0.0001, opt = \"sgd\")\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = False\n",
    "batchSize = 256\n",
    "outputLayerNeurons = 10\n",
    "hiddenLayerNeurons = 128\n",
    "\n",
    "train_X, test_X , train_y, test_y = train_test_split(x, y, test_size=0.10, random_state=11)\n",
    "\n",
    "w1, w2 = network_init(train_X,\n",
    "                               outputLayerNeurons = outputLayerNeurons,\n",
    "                               hiddenLayerNeurons = hiddenLayerNeurons)\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "l1=init(28*28,hiddenLayerNeurons)\n",
    "l2=init(hiddenLayerNeurons,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.3051111111111111\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 200,\n",
    "                      logs=False, alpha = 0.0001, opt = \"adaGrad\", isL2 = True)\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.25066666666666665\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 100,\n",
    "                      logs=False, alpha = 0.0001, opt = \"adaGrad\", isL2 = True)\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.3078888888888889\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 800,\n",
    "                      logs=False, alpha = 0.00001, opt = \"sgd\", isL2 = True)\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = False\n",
    "batchSize = 64\n",
    "outputLayerNeurons = 10\n",
    "hiddenLayerNeurons = 16\n",
    "\n",
    "train_X, test_X , train_y, test_y = train_test_split(x, y, test_size=0.10, random_state=11)\n",
    "\n",
    "w1, w2 = network_init(train_X,\n",
    "                               outputLayerNeurons = outputLayerNeurons,\n",
    "                               hiddenLayerNeurons = hiddenLayerNeurons)\n",
    "\n",
    "np.random.seed(42)\n",
    "l1=init(28*28,hiddenLayerNeurons)\n",
    "l2=init(hiddenLayerNeurons,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.2284920634920635\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 200,\n",
    "                      logs=False, alpha = 0.0001, opt = \"sgd\", isL2 = False)\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.34485714285714286\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 100,\n",
    "                      logs=False, alpha = 0.0001, opt = \"sgd\", isL2 = False)\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = False\n",
    "batchSize = 32\n",
    "outputLayerNeurons = 10\n",
    "hiddenLayerNeurons = 16\n",
    "\n",
    "train_X, test_X , train_y, test_y = train_test_split(x, y, test_size=0.10, random_state=11)\n",
    "\n",
    "w1, w2 = network_init(train_X,\n",
    "                               outputLayerNeurons = outputLayerNeurons,\n",
    "                               hiddenLayerNeurons = hiddenLayerNeurons)\n",
    "\n",
    "np.random.seed(42)\n",
    "l1=init(28*28,hiddenLayerNeurons)\n",
    "l2=init(hiddenLayerNeurons,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.48103174603174603\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 400,\n",
    "                      logs=False, alpha = 0.0001, opt = \"sgd\", isL2 = False)\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.36717460317460315\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 500,\n",
    "                      logs=False, alpha = 0.0001, opt = \"sgd\", isL2 = True)\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.24653968253968253\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 1000,\n",
    "                      logs=False, alpha = 0.0001, opt = \"rmspro\", isL2 = False)\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.31546031746031744\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 1000,\n",
    "                      logs=False, alpha = 0.0001, opt = \"rmspro\", isL2 = True)\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.0001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.17817460317460318\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 500,\n",
    "                      logs=False, alpha = 0.0001, opt = \"adaGrad\", isL2 = True)\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.1918888888888889\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 500,\n",
    "                      logs=False, alpha = 0.0001, opt = \"adaGrad\", isL2 = True)\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.3417142857142857\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 1000,\n",
    "                      logs=False, alpha = 0.0001, opt = \"adam\", isL2 = False)\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.39776190476190476\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 500,\n",
    "                      logs=False, alpha = 0.0001, opt = \"sgd\", isL2 = True, lambda_L2 = 0.01)\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.2999047619047619\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 1000,\n",
    "                      logs=False, alpha = 0.0001, opt = \"rmspro\", isL2 = True)\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accuracy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = False\n",
    "batchSize = 24\n",
    "outputLayerNeurons = 10\n",
    "hiddenLayerNeurons = 8\n",
    "\n",
    "train_X, test_X , train_y, test_y = train_test_split(x, y, test_size=0.10, random_state=11)\n",
    "\n",
    "w1, w2 = network_init(train_X,\n",
    "                               outputLayerNeurons = outputLayerNeurons,\n",
    "                               hiddenLayerNeurons = hiddenLayerNeurons)\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "l1=init(28*28,hiddenLayerNeurons)\n",
    "l2=init(hiddenLayerNeurons,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy : 0.7263809523809523\n"
     ]
    }
   ],
   "source": [
    "wi, wo, loss_, acc_ = train(train_X,\n",
    "                            train_y,\n",
    "                      batchSize = batchSize,\n",
    "                      batches = batches,\n",
    "                      weightsInputLayer = l1.copy(),\n",
    "                      weightsOutputLayer = l2.copy(),\n",
    "                      epochs = 3000,\n",
    "                      logs=False, alpha = 0.0001, opt = \"rmspro\", isL2 = True, lambda_L2 = 0.01)\n",
    "\n",
    "EVE = evaluate(wi.copy(), wo.copy(), train_X, train_y, alpha = 0.001, logs = logs)    \n",
    "print(\"Accurancy : \" + str(EVE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions: \n",
    "* L2 regularization have a big impact on network - the accuracy was higher,\n",
    "* The best accuracy was 72%, with mini batch size 8, 16 hidden neurons, learning rate 0.001 and optimizer RMSpro, L2 regularization with lambda 0.01 and 3000 numbers of epochs ,\n",
    "* Bad impact on network had momentum optimizer with accuracy 20% after 500 epochs,\n",
    "* Good impact on network had Adam optimizer with accuracy 39% after 500 epochs,\n",
    "* Similar impact on network had adaGrad optimizer with accuracy 39% after 500 epochs,\n",
    "* Better impact on network had RMSpro optimizer with accuracy 49% after 150 epochs\n",
    "* The batch size was important - big batch size was having impact on execution time - too much computing. Smaller size had short execution time and the result was faster and in most cases better. \n",
    "* The number of hidden layer neurons also  had a big impact on the network, the smaller size was better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
